{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b23f7e3-ff85-4010-98fd-7a9318fd3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/molmo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n",
      "GPU: NVIDIA L40S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "\n",
      "Config attributes:\n",
      "vocab_size: 152064\n",
      "embedding_size: 152064\n",
      "max_position_embeddings: 4096\n",
      "hidden_size: 3584\n",
      "intermediate_size: 37888\n",
      "num_hidden_layers: 28\n",
      "num_attention_heads: 28\n",
      "layer_norm_eps: 1e-06\n",
      "weight_tying: False\n",
      "use_position_ids: True\n",
      "attention_layer_norm: False\n",
      "num_key_value_heads: 4\n",
      "initializer_range: 0.02\n",
      "use_cache: True\n",
      "rope_theta: 1000000.0\n",
      "clip_qkv: None\n",
      "qkv_bias: True\n",
      "norm_after: False\n",
      "tie_word_embeddings: False\n",
      "layer_norm_type: rms\n",
      "return_dict: True\n",
      "output_hidden_states: False\n",
      "output_attentions: False\n",
      "torchscript: False\n",
      "torch_dtype: torch.float16\n",
      "use_bfloat16: False\n",
      "tf_legacy_loss: False\n",
      "pruned_heads: {}\n",
      "chunk_size_feed_forward: 0\n",
      "is_encoder_decoder: False\n",
      "is_decoder: False\n",
      "cross_attention_hidden_size: None\n",
      "add_cross_attention: False\n",
      "tie_encoder_decoder: False\n",
      "max_length: 20\n",
      "min_length: 0\n",
      "do_sample: False\n",
      "early_stopping: False\n",
      "num_beams: 1\n",
      "num_beam_groups: 1\n",
      "diversity_penalty: 0.0\n",
      "temperature: 1.0\n",
      "top_k: 50\n",
      "top_p: 1.0\n",
      "typical_p: 1.0\n",
      "repetition_penalty: 1.0\n",
      "length_penalty: 1.0\n",
      "no_repeat_ngram_size: 0\n",
      "encoder_no_repeat_ngram_size: 0\n",
      "bad_words_ids: None\n",
      "num_return_sequences: 1\n",
      "output_scores: False\n",
      "return_dict_in_generate: False\n",
      "forced_bos_token_id: None\n",
      "forced_eos_token_id: None\n",
      "remove_invalid_values: False\n",
      "exponential_decay_length_penalty: None\n",
      "suppress_tokens: None\n",
      "begin_suppress_tokens: None\n",
      "architectures: ['MolmoForCausalLM']\n",
      "finetuning_task: None\n",
      "id2label: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "label2id: {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "tokenizer_class: None\n",
      "prefix: None\n",
      "bos_token_id: None\n",
      "pad_token_id: None\n",
      "eos_token_id: None\n",
      "sep_token_id: None\n",
      "decoder_start_token_id: None\n",
      "task_specific_params: None\n",
      "problem_type: None\n",
      "transformers_version: 4.43.3\n",
      "auto_map: {'AutoConfig': 'allenai/Molmo-7B-D-0924--config_molmo.MolmoConfig', 'AutoModelForCausalLM': 'allenai/Molmo-7B-D-0924--modeling_molmo.MolmoForCausalLM'}\n",
      "model_type: molmo\n",
      "\n",
      "Model Structure:\n",
      "Number of parameters: 8,021,025,280\n",
      "Number of trainable parameters: 8,021,025,280\n",
      "\n",
      "Model Methods:\n",
      "Available generation methods: ['can_generate', 'generate', 'generate_from_batch']\n",
      "\n",
      "can_generate method signature:\n",
      "Arguments: ('self',)\n",
      "\n",
      "generate method signature:\n",
      "Arguments: ()\n",
      "\n",
      "generate_from_batch method signature:\n",
      "Arguments: ()\n",
      "\n",
      "Tokenizer Information:\n",
      "Vocabulary size: 152064\n",
      "Model max length: 4096\n",
      "\n",
      "Running processor debug...\n",
      "\n",
      "Raw processor outputs:\n",
      "input_ids: torch.Size([588])\n",
      "images: torch.Size([5, 576, 588])\n",
      "image_input_idx: torch.Size([5, 144])\n",
      "image_masks: torch.Size([5, 576])\n",
      "\n",
      "Debug output received. Proceeding with main script...\n",
      "\n",
      "\n",
      "Starting sequence processing...\n",
      "Number of layers: 28\n",
      "EOS token ID: 151643\n",
      "Initial memory usage: CPU Memory: 1612.81MB, GPU Memory: 15363.12MB\n",
      "\n",
      "Initialized sequence 1:\n",
      "Input shape: torch.Size([1, 325])\n",
      "Generated IDs shape: torch.Size([1, 325])\n",
      "Memory after sequence initialization: CPU Memory: 1613.19MB, GPU Memory: 15365.71MB\n",
      "\n",
      "Initialized sequence 2:\n",
      "Input shape: torch.Size([1, 329])\n",
      "Generated IDs shape: torch.Size([1, 329])\n",
      "Memory after sequence initialization: CPU Memory: 1613.19MB, GPU Memory: 15368.31MB\n",
      "\n",
      "==================================================\n",
      "Processing initial sequences\n",
      "==================================================\n",
      "Max input length: 329\n",
      "\n",
      "Prepared batch inputs:\n",
      "input_ids shape: torch.Size([2, 329])\n",
      "images shape: torch.Size([2, 2, 576, 588])\n",
      "image_input_idx shape: torch.Size([2, 2, 144])\n",
      "image_masks shape: torch.Size([2, 2, 576])\n",
      "attention_mask shape: torch.Size([2, 329])\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant:\n",
      "New token: ' This' (id: 1096)\n",
      "Memory after processing sequence 0: CPU Memory: 1658.19MB, GPU Memory: 15752.80MB\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant:\n",
      "New token: ' The' (id: 576)\n",
      "Memory after processing sequence 1: CPU Memory: 1658.19MB, GPU Memory: 15752.80MB\n",
      "Memory after batch cleanup: CPU Memory: 1658.19MB, GPU Memory: 15752.80MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1658.19MB, GPU Memory: 15752.80MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 329, generated_ids shape = torch.Size([1, 326])\n",
      "Sequence 1: length = 329, generated_ids shape = torch.Size([1, 330])\n",
      "\n",
      "Found 1 different sequence lengths: [329]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 329\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1096], [576]]\n",
      "\n",
      "Calculating attention mask length: 329 (current) + 1 (new) = 330\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 330])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 329, 128]), Value shape: torch.Size([1, 4, 329, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 329, 128]), Value shape: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[329], [329]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 330]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 329, 128]), Value: torch.Size([2, 4, 329, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 330, 128]), Value: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[10300], [2168]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 329\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This\n",
      "New token: ' photograph' (id: 10300)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 327])\n",
      "Memory after processing sequence 0: CPU Memory: 1662.69MB, GPU Memory: 15789.48MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The\n",
      "New token: ' image' (id: 2168)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 331])\n",
      "Memory after processing sequence 1: CPU Memory: 1662.69MB, GPU Memory: 15789.48MB\n",
      "Memory after batch cleanup: CPU Memory: 1662.69MB, GPU Memory: 15789.48MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1662.69MB, GPU Memory: 15789.48MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 330, generated_ids shape = torch.Size([1, 327])\n",
      "Sequence 1: length = 330, generated_ids shape = torch.Size([1, 331])\n",
      "\n",
      "Found 1 different sequence lengths: [330]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 330\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[10300], [2168]]\n",
      "\n",
      "Calculating attention mask length: 330 (current) + 1 (new) = 331\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 331])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 330, 128]), Value shape: torch.Size([1, 4, 330, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 330, 128]), Value shape: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[330], [330]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 331]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 330, 128]), Value: torch.Size([2, 4, 330, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 331, 128]), Value: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[40155], [4933]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 330\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph\n",
      "New token: ' captures' (id: 40155)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 328])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15826.26MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image\n",
      "New token: ' shows' (id: 4933)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 332])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15826.26MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.59MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.59MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 331, generated_ids shape = torch.Size([1, 328])\n",
      "Sequence 1: length = 331, generated_ids shape = torch.Size([1, 332])\n",
      "\n",
      "Found 1 different sequence lengths: [331]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 331\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[40155], [4933]]\n",
      "\n",
      "Calculating attention mask length: 331 (current) + 1 (new) = 332\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 332])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 331, 128]), Value shape: torch.Size([1, 4, 331, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 331, 128]), Value shape: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[331], [331]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 332]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 331, 128]), Value: torch.Size([2, 4, 331, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 332, 128]), Value: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[264], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 331\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 329])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15826.49MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 333])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15826.49MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.70MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.70MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 332, generated_ids shape = torch.Size([1, 329])\n",
      "Sequence 1: length = 332, generated_ids shape = torch.Size([1, 333])\n",
      "\n",
      "Found 1 different sequence lengths: [332]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 332\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[264], [264]]\n",
      "\n",
      "Calculating attention mask length: 332 (current) + 1 (new) = 333\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 333])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 332, 128]), Value shape: torch.Size([1, 4, 332, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 332, 128]), Value shape: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[332], [332]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 333]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 332, 128]), Value: torch.Size([2, 4, 332, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 333, 128]), Value: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2613], [21239]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 332\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a\n",
      "New token: ' small' (id: 2613)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 330])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15826.71MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a\n",
      "New token: ' striking' (id: 21239)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 334])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15826.71MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.81MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.81MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 333, generated_ids shape = torch.Size([1, 330])\n",
      "Sequence 1: length = 333, generated_ids shape = torch.Size([1, 334])\n",
      "\n",
      "Found 1 different sequence lengths: [333]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 333\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2613], [21239]]\n",
      "\n",
      "Calculating attention mask length: 333 (current) + 1 (new) = 334\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 334])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 333, 128]), Value shape: torch.Size([1, 4, 333, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 333, 128]), Value shape: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[333], [333]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 334]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 333, 128]), Value: torch.Size([2, 4, 333, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 334, 128]), Value: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3691], [3691]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 333\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small\n",
      "New token: ' black' (id: 3691)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 331])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15826.93MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking\n",
      "New token: ' black' (id: 3691)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 335])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15826.93MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.93MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15789.93MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 334, generated_ids shape = torch.Size([1, 331])\n",
      "Sequence 1: length = 334, generated_ids shape = torch.Size([1, 335])\n",
      "\n",
      "Found 1 different sequence lengths: [334]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 334\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3691], [3691]]\n",
      "\n",
      "Calculating attention mask length: 334 (current) + 1 (new) = 335\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 335])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 334, 128]), Value shape: torch.Size([1, 4, 334, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 334, 128]), Value shape: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[334], [334]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 335]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 334, 128]), Value: torch.Size([2, 4, 334, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 335, 128]), Value: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[79276], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 334\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black\n",
      "New token: ' Labrador' (id: 79276)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 332])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15827.15MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 336])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15827.15MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.04MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.04MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 335, generated_ids shape = torch.Size([1, 332])\n",
      "Sequence 1: length = 335, generated_ids shape = torch.Size([1, 336])\n",
      "\n",
      "Found 1 different sequence lengths: [335]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 335\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[79276], [323]]\n",
      "\n",
      "Calculating attention mask length: 335 (current) + 1 (new) = 336\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 336])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 335, 128]), Value shape: torch.Size([1, 4, 335, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 335, 128]), Value shape: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[335], [335]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 336]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 335, 128]), Value: torch.Size([2, 4, 335, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 336, 128]), Value: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[10392], [4158]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 335\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador\n",
      "New token: ' Ret' (id: 10392)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 333])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15827.37MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and\n",
      "New token: ' white' (id: 4158)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 337])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15827.37MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.15MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.15MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 336, generated_ids shape = torch.Size([1, 333])\n",
      "Sequence 1: length = 336, generated_ids shape = torch.Size([1, 337])\n",
      "\n",
      "Found 1 different sequence lengths: [336]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 336\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[10392], [4158]]\n",
      "\n",
      "Calculating attention mask length: 336 (current) + 1 (new) = 337\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 337])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 336, 128]), Value shape: torch.Size([1, 4, 336, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 336, 128]), Value shape: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[336], [336]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 337]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 336, 128]), Value: torch.Size([2, 4, 336, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 337, 128]), Value: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[461], [40784]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 336\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Ret\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Ret\n",
      "New token: 'ri' (id: 461)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 334])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15827.59MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white\n",
      "New token: ' aerial' (id: 40784)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 338])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15827.59MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.26MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.26MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 337, generated_ids shape = torch.Size([1, 334])\n",
      "Sequence 1: length = 337, generated_ids shape = torch.Size([1, 338])\n",
      "\n",
      "Found 1 different sequence lengths: [337]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 337\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[461], [40784]]\n",
      "\n",
      "Calculating attention mask length: 337 (current) + 1 (new) = 338\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 338])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 337, 128]), Value shape: torch.Size([1, 4, 337, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 337, 128]), Value shape: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[337], [337]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 338]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 337, 128]), Value: torch.Size([2, 4, 337, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 338, 128]), Value: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2054], [1651]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 337\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retri\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retri\n",
      "New token: 'ever' (id: 2054)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 335])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15827.81MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial\n",
      "New token: ' view' (id: 1651)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 339])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15827.81MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.37MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.37MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 338, generated_ids shape = torch.Size([1, 335])\n",
      "Sequence 1: length = 338, generated_ids shape = torch.Size([1, 339])\n",
      "\n",
      "Found 1 different sequence lengths: [338]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 338\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2054], [1651]]\n",
      "\n",
      "Calculating attention mask length: 338 (current) + 1 (new) = 339\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 339])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 338, 128]), Value shape: torch.Size([1, 4, 338, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 338, 128]), Value shape: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[338], [338]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 339]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 338, 128]), Value: torch.Size([2, 4, 338, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 339, 128]), Value: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[41189], [315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 338\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever\n",
      "New token: ' puppy' (id: 41189)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 336])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15828.03MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 340])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15828.03MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.49MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.49MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 339, generated_ids shape = torch.Size([1, 336])\n",
      "Sequence 1: length = 339, generated_ids shape = torch.Size([1, 340])\n",
      "\n",
      "Found 1 different sequence lengths: [339]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 339\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[41189], [315]]\n",
      "\n",
      "Calculating attention mask length: 339 (current) + 1 (new) = 340\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 340])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 339, 128]), Value shape: torch.Size([1, 4, 339, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 339, 128]), Value shape: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[339], [339]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 340]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 339, 128]), Value: torch.Size([2, 4, 339, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 340, 128]), Value: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [1532]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 339\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 337])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15828.26MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of\n",
      "New token: ' New' (id: 1532)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 341])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15828.26MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.60MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.60MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 340, generated_ids shape = torch.Size([1, 337])\n",
      "Sequence 1: length = 340, generated_ids shape = torch.Size([1, 341])\n",
      "\n",
      "Found 1 different sequence lengths: [340]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 340\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [1532]]\n",
      "\n",
      "Calculating attention mask length: 340 (current) + 1 (new) = 341\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 341])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 340, 128]), Value shape: torch.Size([1, 4, 340, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 340, 128]), Value shape: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[340], [340]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 341]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 340, 128]), Value: torch.Size([2, 4, 340, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 341, 128]), Value: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[4363], [4261]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 340\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy,\n",
      "New token: ' likely' (id: 4363)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 338])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15828.48MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New\n",
      "New token: ' York' (id: 4261)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 342])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15828.48MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.71MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.71MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 341, generated_ids shape = torch.Size([1, 338])\n",
      "Sequence 1: length = 341, generated_ids shape = torch.Size([1, 342])\n",
      "\n",
      "Found 1 different sequence lengths: [341]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 341\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[4363], [4261]]\n",
      "\n",
      "Calculating attention mask length: 341 (current) + 1 (new) = 342\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 342])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 341, 128]), Value shape: torch.Size([1, 4, 341, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 341, 128]), Value shape: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[341], [341]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 342]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 341, 128]), Value: torch.Size([2, 4, 341, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 342, 128]), Value: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2163], [4311]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 341\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely\n",
      "New token: ' around' (id: 2163)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 339])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15828.70MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York\n",
      "New token: ' City' (id: 4311)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 343])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15828.70MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.82MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.82MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 342, generated_ids shape = torch.Size([1, 339])\n",
      "Sequence 1: length = 342, generated_ids shape = torch.Size([1, 343])\n",
      "\n",
      "Found 1 different sequence lengths: [342]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 342\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2163], [4311]]\n",
      "\n",
      "Calculating attention mask length: 342 (current) + 1 (new) = 343\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 343])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 342, 128]), Value shape: torch.Size([1, 4, 342, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 342, 128]), Value shape: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[342], [342]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 343]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 342, 128]), Value: torch.Size([2, 4, 342, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 343, 128]), Value: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[4743], [594]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 342\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around\n",
      "New token: ' six' (id: 4743)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 340])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15828.92MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City\n",
      "New token: ''s' (id: 594)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 344])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15828.92MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.93MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15790.93MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 343, generated_ids shape = torch.Size([1, 340])\n",
      "Sequence 1: length = 343, generated_ids shape = torch.Size([1, 344])\n",
      "\n",
      "Found 1 different sequence lengths: [343]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 343\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[4743], [594]]\n",
      "\n",
      "Calculating attention mask length: 343 (current) + 1 (new) = 344\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 344])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 343, 128]), Value shape: torch.Size([1, 4, 343, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 343, 128]), Value shape: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[343], [343]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 344]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 343, 128]), Value: torch.Size([2, 4, 343, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 344, 128]), Value: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3951], [26277]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 343\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six\n",
      "New token: ' months' (id: 3951)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 341])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15829.14MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's\n",
      "New token: ' iconic' (id: 26277)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 345])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15829.14MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.05MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.05MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 344, generated_ids shape = torch.Size([1, 341])\n",
      "Sequence 1: length = 344, generated_ids shape = torch.Size([1, 345])\n",
      "\n",
      "Found 1 different sequence lengths: [344]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 344\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3951], [26277]]\n",
      "\n",
      "Calculating attention mask length: 344 (current) + 1 (new) = 345\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 345])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 344, 128]), Value shape: torch.Size([1, 4, 344, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 344, 128]), Value shape: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[344], [344]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 345]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 344, 128]), Value: torch.Size([2, 4, 344, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 345, 128]), Value: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2310], [87739]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 344\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months\n",
      "New token: ' old' (id: 2310)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 342])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15829.36MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic\n",
      "New token: ' skyline' (id: 87739)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 346])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15829.36MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.16MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.16MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 345, generated_ids shape = torch.Size([1, 342])\n",
      "Sequence 1: length = 345, generated_ids shape = torch.Size([1, 346])\n",
      "\n",
      "Found 1 different sequence lengths: [345]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 345\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2310], [87739]]\n",
      "\n",
      "Calculating attention mask length: 345 (current) + 1 (new) = 346\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 346])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 345, 128]), Value shape: torch.Size([1, 4, 345, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 345, 128]), Value shape: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[345], [345]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 346]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 345, 128]), Value: torch.Size([2, 4, 345, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 346, 128]), Value: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [13]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 345\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 343])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15829.58MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 347])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15829.58MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.27MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.27MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 346, generated_ids shape = torch.Size([1, 343])\n",
      "Sequence 1: length = 346, generated_ids shape = torch.Size([1, 347])\n",
      "\n",
      "Found 1 different sequence lengths: [346]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 346\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [13]]\n",
      "\n",
      "Calculating attention mask length: 346 (current) + 1 (new) = 347\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 347])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 346, 128]), Value shape: torch.Size([1, 4, 346, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 346, 128]), Value shape: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[346], [346]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 347]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 346, 128]), Value: torch.Size([2, 4, 346, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 347, 128]), Value: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11699], [576]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 346\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old,\n",
      "New token: ' sitting' (id: 11699)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 344])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15829.81MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline.\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 348])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15829.81MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.38MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.38MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 347, generated_ids shape = torch.Size([1, 344])\n",
      "Sequence 1: length = 347, generated_ids shape = torch.Size([1, 348])\n",
      "\n",
      "Found 1 different sequence lengths: [347]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 347\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11699], [576]]\n",
      "\n",
      "Calculating attention mask length: 347 (current) + 1 (new) = 348\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 348])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 347, 128]), Value shape: torch.Size([1, 4, 347, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 347, 128]), Value shape: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[347], [347]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 348]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 347, 128]), Value: torch.Size([2, 4, 347, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 348, 128]), Value: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[389], [10300]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 347\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting\n",
      "New token: ' on' (id: 389)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 345])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15830.03MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The\n",
      "New token: ' photograph' (id: 10300)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 349])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.03MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.49MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.49MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 348, generated_ids shape = torch.Size([1, 345])\n",
      "Sequence 1: length = 348, generated_ids shape = torch.Size([1, 349])\n",
      "\n",
      "Found 1 different sequence lengths: [348]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 348\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[389], [10300]]\n",
      "\n",
      "Calculating attention mask length: 348 (current) + 1 (new) = 349\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 349])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 348, 128]), Value shape: torch.Size([1, 4, 348, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 348, 128]), Value shape: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[348], [348]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 349]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 348, 128]), Value: torch.Size([2, 4, 348, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 349, 128]), Value: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[264], [40155]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 348\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 346])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15830.25MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph\n",
      "New token: ' captures' (id: 40155)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 350])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.25MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.61MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.61MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 349, generated_ids shape = torch.Size([1, 346])\n",
      "Sequence 1: length = 349, generated_ids shape = torch.Size([1, 350])\n",
      "\n",
      "Found 1 different sequence lengths: [349]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 349\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[264], [40155]]\n",
      "\n",
      "Calculating attention mask length: 349 (current) + 1 (new) = 350\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 350])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 349, 128]), Value shape: torch.Size([1, 4, 349, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 349, 128]), Value shape: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[349], [349]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 350]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 349, 128]), Value: torch.Size([2, 4, 349, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 350, 128]), Value: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9104], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 349\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a\n",
      "New token: ' weather' (id: 9104)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 347])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15830.47MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 351])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.47MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.72MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.72MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 350, generated_ids shape = torch.Size([1, 347])\n",
      "Sequence 1: length = 350, generated_ids shape = torch.Size([1, 351])\n",
      "\n",
      "Found 1 different sequence lengths: [350]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 350\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9104], [279]]\n",
      "\n",
      "Calculating attention mask length: 350 (current) + 1 (new) = 351\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 351])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 350, 128]), Value shape: torch.Size([1, 4, 350, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 350, 128]), Value shape: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[350], [350]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 351]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 350, 128]), Value: torch.Size([2, 4, 350, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 351, 128]), Value: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[291], [27950]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 350\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weather\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weather\n",
      "New token: 'ed' (id: 291)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 348])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15830.69MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the\n",
      "New token: ' dense' (id: 27950)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 352])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.69MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.83MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.83MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 351, generated_ids shape = torch.Size([1, 348])\n",
      "Sequence 1: length = 351, generated_ids shape = torch.Size([1, 352])\n",
      "\n",
      "Found 1 different sequence lengths: [351]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 351\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[291], [27950]]\n",
      "\n",
      "Calculating attention mask length: 351 (current) + 1 (new) = 352\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 352])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 351, 128]), Value shape: torch.Size([1, 4, 351, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 351, 128]), Value shape: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[351], [351]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 352]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 351, 128]), Value: torch.Size([2, 4, 351, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 352, 128]), Value: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[22360], [15662]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 351\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered\n",
      "New token: ' wooden' (id: 22360)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 349])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15830.91MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense\n",
      "New token: ' urban' (id: 15662)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 353])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.91MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.94MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15791.94MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 352, generated_ids shape = torch.Size([1, 349])\n",
      "Sequence 1: length = 352, generated_ids shape = torch.Size([1, 353])\n",
      "\n",
      "Found 1 different sequence lengths: [352]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 352\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[22360], [15662]]\n",
      "\n",
      "Calculating attention mask length: 352 (current) + 1 (new) = 353\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 353])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 352, 128]), Value shape: torch.Size([1, 4, 352, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 352, 128]), Value shape: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[352], [352]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 353]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 352, 128]), Value: torch.Size([2, 4, 352, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 353, 128]), Value: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9530], [18414]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 352\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden\n",
      "New token: ' deck' (id: 9530)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 350])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15831.13MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban\n",
      "New token: ' landscape' (id: 18414)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 354])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15831.13MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.05MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.05MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 353, generated_ids shape = torch.Size([1, 350])\n",
      "Sequence 1: length = 353, generated_ids shape = torch.Size([1, 354])\n",
      "\n",
      "Found 1 different sequence lengths: [353]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 353\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9530], [18414]]\n",
      "\n",
      "Calculating attention mask length: 353 (current) + 1 (new) = 354\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 354])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 353, 128]), Value shape: torch.Size([1, 4, 353, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 353, 128]), Value shape: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[353], [353]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 354]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 353, 128]), Value: torch.Size([2, 4, 353, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 354, 128]), Value: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [448]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 353\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 351])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15831.36MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape\n",
      "New token: ' with' (id: 448)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 355])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15831.36MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.17MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.17MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 354, generated_ids shape = torch.Size([1, 351])\n",
      "Sequence 1: length = 354, generated_ids shape = torch.Size([1, 355])\n",
      "\n",
      "Found 1 different sequence lengths: [354]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 354\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [448]]\n",
      "\n",
      "Calculating attention mask length: 354 (current) + 1 (new) = 355\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 355])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 354, 128]), Value shape: torch.Size([1, 4, 354, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 354, 128]), Value shape: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[354], [354]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 355]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 354, 128]), Value: torch.Size([2, 4, 354, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 355, 128]), Value: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[576], [12114]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 354\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 352])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15831.58MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with\n",
      "New token: ' numerous' (id: 12114)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 356])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15831.58MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.28MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.28MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 355, generated_ids shape = torch.Size([1, 352])\n",
      "Sequence 1: length = 355, generated_ids shape = torch.Size([1, 356])\n",
      "\n",
      "Found 1 different sequence lengths: [355]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 355\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[576], [12114]]\n",
      "\n",
      "Calculating attention mask length: 355 (current) + 1 (new) = 356\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 356])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 355, 128]), Value shape: torch.Size([1, 4, 355, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 355, 128]), Value shape: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[355], [355]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 356]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 355, 128]), Value: torch.Size([2, 4, 355, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 356, 128]), Value: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9530], [84321]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 355\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The\n",
      "New token: ' deck' (id: 9530)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 353])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15831.80MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous\n",
      "New token: ' skys' (id: 84321)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 357])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15831.80MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.39MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.39MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 356, generated_ids shape = torch.Size([1, 353])\n",
      "Sequence 1: length = 356, generated_ids shape = torch.Size([1, 357])\n",
      "\n",
      "Found 1 different sequence lengths: [356]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 356\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9530], [84321]]\n",
      "\n",
      "Calculating attention mask length: 356 (current) + 1 (new) = 357\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 357])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 356, 128]), Value shape: torch.Size([1, 4, 356, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 356, 128]), Value shape: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[356], [356]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 357]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 356, 128]), Value: torch.Size([2, 4, 356, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 357, 128]), Value: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[594], [98721]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 356\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck\n",
      "New token: ''s' (id: 594)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 354])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15832.02MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skys\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skys\n",
      "New token: 'crap' (id: 98721)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 358])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15832.02MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.50MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.50MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 357, generated_ids shape = torch.Size([1, 354])\n",
      "Sequence 1: length = 357, generated_ids shape = torch.Size([1, 358])\n",
      "\n",
      "Found 1 different sequence lengths: [357]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 357\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[594], [98721]]\n",
      "\n",
      "Calculating attention mask length: 357 (current) + 1 (new) = 358\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 358])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 357, 128]), Value shape: torch.Size([1, 4, 357, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 357, 128]), Value shape: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[357], [357]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 358]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 357, 128]), Value: torch.Size([2, 4, 357, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 358, 128]), Value: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[625], [388]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 357\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's\n",
      "New token: ' pl' (id: 625)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 355])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15832.24MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrap\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrap\n",
      "New token: 'ers' (id: 388)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 359])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15832.24MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.61MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.61MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 358, generated_ids shape = torch.Size([1, 355])\n",
      "Sequence 1: length = 358, generated_ids shape = torch.Size([1, 359])\n",
      "\n",
      "Found 1 different sequence lengths: [358]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 358\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[625], [388]]\n",
      "\n",
      "Calculating attention mask length: 358 (current) + 1 (new) = 359\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 359])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 358, 128]), Value shape: torch.Size([1, 4, 358, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 358, 128]), Value shape: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[358], [358]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 359]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 358, 128]), Value: torch.Size([2, 4, 358, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 359, 128]), Value: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[4039], [315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 358\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's pl\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's pl\n",
      "New token: 'anks' (id: 4039)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 356])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15832.46MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 360])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15832.46MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.73MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.73MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 359, generated_ids shape = torch.Size([1, 356])\n",
      "Sequence 1: length = 359, generated_ids shape = torch.Size([1, 360])\n",
      "\n",
      "Found 1 different sequence lengths: [359]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 359\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[4039], [315]]\n",
      "\n",
      "Calculating attention mask length: 359 (current) + 1 (new) = 360\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 360])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 359, 128]), Value shape: torch.Size([1, 4, 359, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 359, 128]), Value shape: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[359], [359]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 360]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 359, 128]), Value: torch.Size([2, 4, 359, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 360, 128]), Value: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [28765]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 359\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 357])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15832.68MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of\n",
      "New token: ' varying' (id: 28765)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 361])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15832.68MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.84MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.84MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 360, generated_ids shape = torch.Size([1, 357])\n",
      "Sequence 1: length = 360, generated_ids shape = torch.Size([1, 361])\n",
      "\n",
      "Found 1 different sequence lengths: [360]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 360\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [28765]]\n",
      "\n",
      "Calculating attention mask length: 360 (current) + 1 (new) = 361\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 361])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 360, 128]), Value shape: torch.Size([1, 4, 360, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 360, 128]), Value shape: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[360], [360]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 361]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 360, 128]), Value: torch.Size([2, 4, 360, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 361, 128]), Value: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[892], [35294]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 360\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks,\n",
      "New token: ' which' (id: 892)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 358])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15832.91MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying\n",
      "New token: ' heights' (id: 35294)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 362])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15832.91MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.95MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15792.95MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 361, generated_ids shape = torch.Size([1, 358])\n",
      "Sequence 1: length = 361, generated_ids shape = torch.Size([1, 362])\n",
      "\n",
      "Found 1 different sequence lengths: [361]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 361\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[892], [35294]]\n",
      "\n",
      "Calculating attention mask length: 361 (current) + 1 (new) = 362\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 362])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 361, 128]), Value shape: torch.Size([1, 4, 361, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 361, 128]), Value shape: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[361], [361]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 362]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 361, 128]), Value: torch.Size([2, 4, 361, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 362, 128]), Value: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[525], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 361\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which\n",
      "New token: ' are' (id: 525)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 359])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15833.13MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 363])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15833.13MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.06MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.06MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 362, generated_ids shape = torch.Size([1, 359])\n",
      "Sequence 1: length = 362, generated_ids shape = torch.Size([1, 363])\n",
      "\n",
      "Found 1 different sequence lengths: [362]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 362\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[525], [323]]\n",
      "\n",
      "Calculating attention mask length: 362 (current) + 1 (new) = 363\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 363])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 362, 128]), Value shape: torch.Size([1, 4, 362, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 362, 128]), Value shape: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[362], [362]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 363]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 362, 128]), Value: torch.Size([2, 4, 362, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 363, 128]), Value: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[264], [42463]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 362\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 360])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15833.35MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and\n",
      "New token: ' architectural' (id: 42463)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 364])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15833.35MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.17MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.17MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 363, generated_ids shape = torch.Size([1, 360])\n",
      "Sequence 1: length = 363, generated_ids shape = torch.Size([1, 364])\n",
      "\n",
      "Found 1 different sequence lengths: [363]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 363\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[264], [42463]]\n",
      "\n",
      "Calculating attention mask length: 363 (current) + 1 (new) = 364\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 364])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 363, 128]), Value shape: torch.Size([1, 4, 363, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 363, 128]), Value shape: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[363], [363]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 364]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 363, 128]), Value: torch.Size([2, 4, 363, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 364, 128]), Value: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[6514], [9222]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 363\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a\n",
      "New token: ' mix' (id: 6514)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 361])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15833.57MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural\n",
      "New token: ' styles' (id: 9222)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 365])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15833.57MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.29MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.29MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 364, generated_ids shape = torch.Size([1, 361])\n",
      "Sequence 1: length = 364, generated_ids shape = torch.Size([1, 365])\n",
      "\n",
      "Found 1 different sequence lengths: [364]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 364\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[6514], [9222]]\n",
      "\n",
      "Calculating attention mask length: 364 (current) + 1 (new) = 365\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 365])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 364, 128]), Value shape: torch.Size([1, 4, 364, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 364, 128]), Value shape: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[364], [364]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 365]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 364, 128]), Value: torch.Size([2, 4, 364, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 365, 128]), Value: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[315], [13]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 364\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 362])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15833.79MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 366])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15833.79MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.40MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.40MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 365, generated_ids shape = torch.Size([1, 362])\n",
      "Sequence 1: length = 365, generated_ids shape = torch.Size([1, 366])\n",
      "\n",
      "Found 1 different sequence lengths: [365]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 365\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[315], [13]]\n",
      "\n",
      "Calculating attention mask length: 365 (current) + 1 (new) = 366\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 366])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 365, 128]), Value shape: torch.Size([1, 4, 365, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 365, 128]), Value shape: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[365], [365]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 366]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 365, 128]), Value: torch.Size([2, 4, 365, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 366, 128]), Value: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3100], [4329]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 365\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of\n",
      "New token: ' light' (id: 3100)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 363])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15834.01MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles.\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles.\n",
      "New token: ' Some' (id: 4329)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 367])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15834.01MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.51MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.51MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 366, generated_ids shape = torch.Size([1, 363])\n",
      "Sequence 1: length = 366, generated_ids shape = torch.Size([1, 367])\n",
      "\n",
      "Found 1 different sequence lengths: [366]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 366\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3100], [4329]]\n",
      "\n",
      "Calculating attention mask length: 366 (current) + 1 (new) = 367\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 367])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 366, 128]), Value shape: torch.Size([1, 4, 366, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 366, 128]), Value shape: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[366], [366]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 367]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 366, 128]), Value: torch.Size([2, 4, 366, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 367, 128]), Value: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[323], [13702]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 366\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 364])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15834.24MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some\n",
      "New token: ' buildings' (id: 13702)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 368])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15834.24MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.62MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.62MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 367, generated_ids shape = torch.Size([1, 364])\n",
      "Sequence 1: length = 367, generated_ids shape = torch.Size([1, 368])\n",
      "\n",
      "Found 1 different sequence lengths: [367]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 367\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[323], [13702]]\n",
      "\n",
      "Calculating attention mask length: 367 (current) + 1 (new) = 368\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 368])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 367, 128]), Value shape: torch.Size([1, 4, 367, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 367, 128]), Value shape: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[367], [367]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 368]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 367, 128]), Value: torch.Size([2, 4, 367, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 368, 128]), Value: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[6319], [614]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 367\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and\n",
      "New token: ' dark' (id: 6319)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 365])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15834.46MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings\n",
      "New token: ' have' (id: 614)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 369])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15834.46MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.74MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.74MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 368, generated_ids shape = torch.Size([1, 365])\n",
      "Sequence 1: length = 368, generated_ids shape = torch.Size([1, 369])\n",
      "\n",
      "Found 1 different sequence lengths: [368]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 368\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[6319], [614]]\n",
      "\n",
      "Calculating attention mask length: 368 (current) + 1 (new) = 369\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 369])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 368, 128]), Value shape: torch.Size([1, 4, 368, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 368, 128]), Value shape: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[368], [368]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 369]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 368, 128]), Value: torch.Size([2, 4, 368, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 369, 128]), Value: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13876], [14283]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 368\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark\n",
      "New token: ' brown' (id: 13876)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 366])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15834.68MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have\n",
      "New token: ' pointed' (id: 14283)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 370])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15834.68MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.85MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.85MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 369, generated_ids shape = torch.Size([1, 366])\n",
      "Sequence 1: length = 369, generated_ids shape = torch.Size([1, 370])\n",
      "\n",
      "Found 1 different sequence lengths: [369]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 369\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13876], [14283]]\n",
      "\n",
      "Calculating attention mask length: 369 (current) + 1 (new) = 370\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 370])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 369, 128]), Value shape: torch.Size([1, 4, 369, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 369, 128]), Value shape: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[369], [369]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 370]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 369, 128]), Value: torch.Size([2, 4, 369, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 370, 128]), Value: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[448], [978]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 369\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown\n",
      "New token: ' with' (id: 448)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 367])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15834.90MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed\n",
      "New token: ' sp' (id: 978)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 371])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15834.90MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.96MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15793.96MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 370, generated_ids shape = torch.Size([1, 367])\n",
      "Sequence 1: length = 370, generated_ids shape = torch.Size([1, 371])\n",
      "\n",
      "Found 1 different sequence lengths: [370]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 370\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[448], [978]]\n",
      "\n",
      "Calculating attention mask length: 370 (current) + 1 (new) = 371\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 371])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 370, 128]), Value shape: torch.Size([1, 4, 370, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 370, 128]), Value shape: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[370], [370]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 371]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 370, 128]), Value: torch.Size([2, 4, 370, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 371, 128]), Value: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9434], [3861]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 370\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with\n",
      "New token: ' visible' (id: 9434)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 368])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15835.12MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed sp\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed sp\n",
      "New token: 'ires' (id: 3861)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 372])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15835.12MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.07MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.07MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 371, generated_ids shape = torch.Size([1, 368])\n",
      "Sequence 1: length = 371, generated_ids shape = torch.Size([1, 372])\n",
      "\n",
      "Found 1 different sequence lengths: [371]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 371\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9434], [3861]]\n",
      "\n",
      "Calculating attention mask length: 371 (current) + 1 (new) = 372\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 372])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 371, 128]), Value shape: torch.Size([1, 4, 371, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 371, 128]), Value shape: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[371], [371]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 372]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 371, 128]), Value: torch.Size([2, 4, 371, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 372, 128]), Value: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[44863], [11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 371\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible\n",
      "New token: ' cracks' (id: 44863)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 369])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15835.34MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 373])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15835.34MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.18MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.18MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 372, generated_ids shape = torch.Size([1, 369])\n",
      "Sequence 1: length = 372, generated_ids shape = torch.Size([1, 373])\n",
      "\n",
      "Found 1 different sequence lengths: [372]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 372\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[44863], [11]]\n",
      "\n",
      "Calculating attention mask length: 372 (current) + 1 (new) = 373\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 373])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 372, 128]), Value shape: torch.Size([1, 4, 372, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 372, 128]), Value shape: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[372], [372]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 373]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 372, 128]), Value: torch.Size([2, 4, 372, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 373, 128]), Value: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[323], [1393]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 372\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 370])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15835.56MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires,\n",
      "New token: ' while' (id: 1393)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 374])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15835.56MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.30MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.30MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 373, generated_ids shape = torch.Size([1, 370])\n",
      "Sequence 1: length = 373, generated_ids shape = torch.Size([1, 374])\n",
      "\n",
      "Found 1 different sequence lengths: [373]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 373\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[323], [1393]]\n",
      "\n",
      "Calculating attention mask length: 373 (current) + 1 (new) = 374\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 374])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 373, 128]), Value shape: torch.Size([1, 4, 373, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 373, 128]), Value shape: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[373], [373]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 374]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 373, 128]), Value: torch.Size([2, 4, 373, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 374, 128]), Value: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[60217], [3800]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 373\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and\n",
      "New token: ' knots' (id: 60217)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 371])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15835.79MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while\n",
      "New token: ' others' (id: 3800)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 375])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15835.79MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.41MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.41MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 374, generated_ids shape = torch.Size([1, 371])\n",
      "Sequence 1: length = 374, generated_ids shape = torch.Size([1, 375])\n",
      "\n",
      "Found 1 different sequence lengths: [374]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 374\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[60217], [3800]]\n",
      "\n",
      "Calculating attention mask length: 374 (current) + 1 (new) = 375\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 375])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 374, 128]), Value shape: torch.Size([1, 4, 374, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 374, 128]), Value shape: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[374], [374]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 375]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 374, 128]), Value: torch.Size([2, 4, 374, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 375, 128]), Value: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [4565]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 374\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 372])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15836.01MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others\n",
      "New token: ' feature' (id: 4565)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 376])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15836.01MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.52MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.52MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 375, generated_ids shape = torch.Size([1, 372])\n",
      "Sequence 1: length = 375, generated_ids shape = torch.Size([1, 376])\n",
      "\n",
      "Found 1 different sequence lengths: [375]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 375\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [4565]]\n",
      "\n",
      "Calculating attention mask length: 375 (current) + 1 (new) = 376\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 376])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 375, 128]), Value shape: torch.Size([1, 4, 375, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 375, 128]), Value shape: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[375], [375]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 376]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 375, 128]), Value: torch.Size([2, 4, 375, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 376, 128]), Value: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3410], [10063]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 375\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots,\n",
      "New token: ' provide' (id: 3410)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 373])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15836.23MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature\n",
      "New token: ' flat' (id: 10063)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 377])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15836.23MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.63MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.63MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 376, generated_ids shape = torch.Size([1, 373])\n",
      "Sequence 1: length = 376, generated_ids shape = torch.Size([1, 377])\n",
      "\n",
      "Found 1 different sequence lengths: [376]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 376\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3410], [10063]]\n",
      "\n",
      "Calculating attention mask length: 376 (current) + 1 (new) = 377\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 377])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 376, 128]), Value shape: torch.Size([1, 4, 376, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 376, 128]), Value shape: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[376], [376]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 377]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 376, 128]), Value: torch.Size([2, 4, 376, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 377, 128]), Value: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[264], [76295]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 376\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 374])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15836.45MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat\n",
      "New token: ' roofs' (id: 76295)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 378])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15836.45MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.75MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.75MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 377, generated_ids shape = torch.Size([1, 374])\n",
      "Sequence 1: length = 377, generated_ids shape = torch.Size([1, 378])\n",
      "\n",
      "Found 1 different sequence lengths: [377]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 377\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[264], [76295]]\n",
      "\n",
      "Calculating attention mask length: 377 (current) + 1 (new) = 378\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 378])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 377, 128]), Value shape: torch.Size([1, 4, 377, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 377, 128]), Value shape: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[377], [377]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 378]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 377, 128]), Value: torch.Size([2, 4, 377, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 378, 128]), Value: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[57272], [382]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 377\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a\n",
      "New token: ' rustic' (id: 57272)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 375])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15836.67MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs\n",
      "New token: '.\n",
      "\n",
      "' (id: 382)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 379])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15836.67MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.86MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.86MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 378, generated_ids shape = torch.Size([1, 375])\n",
      "Sequence 1: length = 378, generated_ids shape = torch.Size([1, 379])\n",
      "\n",
      "Found 1 different sequence lengths: [378]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 378\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[57272], [382]]\n",
      "\n",
      "Calculating attention mask length: 378 (current) + 1 (new) = 379\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 379])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 378, 128]), Value shape: torch.Size([1, 4, 378, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 378, 128]), Value shape: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[378], [378]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 379]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 378, 128]), Value: torch.Size([2, 4, 378, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 379, 128]), Value: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[38477], [785]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 378\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic\n",
      "New token: ' backdrop' (id: 38477)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 376])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15836.89MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "\n",
      "New token: 'The' (id: 785)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 380])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15836.89MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.97MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15794.97MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 379, generated_ids shape = torch.Size([1, 376])\n",
      "Sequence 1: length = 379, generated_ids shape = torch.Size([1, 380])\n",
      "\n",
      "Found 1 different sequence lengths: [379]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 379\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[38477], [785]]\n",
      "\n",
      "Calculating attention mask length: 379 (current) + 1 (new) = 380\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 380])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 379, 128]), Value shape: torch.Size([1, 4, 379, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 379, 128]), Value shape: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[379], [379]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 380]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 379, 128]), Value: torch.Size([2, 4, 379, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 380, 128]), Value: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [18037]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 379\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 377])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15837.12MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The\n",
      "New token: ' composition' (id: 18037)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 381])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15837.12MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.08MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.08MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 380, generated_ids shape = torch.Size([1, 377])\n",
      "Sequence 1: length = 380, generated_ids shape = torch.Size([1, 381])\n",
      "\n",
      "Found 1 different sequence lengths: [380]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 380\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [18037]]\n",
      "\n",
      "Calculating attention mask length: 380 (current) + 1 (new) = 381\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 381])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 380, 128]), Value shape: torch.Size([1, 4, 380, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 380, 128]), Value shape: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[380], [380]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 381]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 380, 128]), Value: torch.Size([2, 4, 380, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 381, 128]), Value: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[576], [374]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 380\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 378])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15837.34MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition\n",
      "New token: ' is' (id: 374)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 382])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15837.34MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.19MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.19MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 381, generated_ids shape = torch.Size([1, 378])\n",
      "Sequence 1: length = 381, generated_ids shape = torch.Size([1, 382])\n",
      "\n",
      "Found 1 different sequence lengths: [381]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 381\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[576], [374]]\n",
      "\n",
      "Calculating attention mask length: 381 (current) + 1 (new) = 382\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 382])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 381, 128]), Value shape: torch.Size([1, 4, 381, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 381, 128]), Value shape: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[381], [381]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 382]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 381, 128]), Value: torch.Size([2, 4, 381, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 382, 128]), Value: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[41189], [29701]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 381\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The\n",
      "New token: ' puppy' (id: 41189)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 379])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15837.56MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is\n",
      "New token: ' dominated' (id: 29701)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 383])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15837.56MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.31MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.31MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 382, generated_ids shape = torch.Size([1, 379])\n",
      "Sequence 1: length = 382, generated_ids shape = torch.Size([1, 383])\n",
      "\n",
      "Found 1 different sequence lengths: [382]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 382\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[41189], [29701]]\n",
      "\n",
      "Calculating attention mask length: 382 (current) + 1 (new) = 383\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 383])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 382, 128]), Value shape: torch.Size([1, 4, 382, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 382, 128]), Value shape: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[382], [382]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 383]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 382, 128]), Value: torch.Size([2, 4, 382, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 383, 128]), Value: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [553]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 382\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 380])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15837.78MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated\n",
      "New token: ' by' (id: 553)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 384])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15837.78MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.42MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.42MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 383, generated_ids shape = torch.Size([1, 380])\n",
      "Sequence 1: length = 383, generated_ids shape = torch.Size([1, 384])\n",
      "\n",
      "Found 1 different sequence lengths: [383]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 383\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [553]]\n",
      "\n",
      "Calculating attention mask length: 383 (current) + 1 (new) = 384\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 384])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 383, 128]), Value shape: torch.Size([1, 4, 383, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 383, 128]), Value shape: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[383], [383]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 384]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 383, 128]), Value: torch.Size([2, 4, 383, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 384, 128]), Value: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[448], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 383\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy,\n",
      "New token: ' with' (id: 448)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 381])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15838.00MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 385])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15838.00MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.53MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.53MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 384, generated_ids shape = torch.Size([1, 381])\n",
      "Sequence 1: length = 384, generated_ids shape = torch.Size([1, 385])\n",
      "\n",
      "Found 1 different sequence lengths: [384]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 384\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[448], [264]]\n",
      "\n",
      "Calculating attention mask length: 384 (current) + 1 (new) = 385\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 385])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 384, 128]), Value shape: torch.Size([1, 4, 384, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 384, 128]), Value shape: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[384], [384]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 385]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 384, 128]), Value: torch.Size([2, 4, 384, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 385, 128]), Value: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [6514]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 384\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 382])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15838.23MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a\n",
      "New token: ' mix' (id: 6514)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 386])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15838.23MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.64MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.64MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 385, generated_ids shape = torch.Size([1, 382])\n",
      "Sequence 1: length = 385, generated_ids shape = torch.Size([1, 386])\n",
      "\n",
      "Found 1 different sequence lengths: [385]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 385\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [6514]]\n",
      "\n",
      "Calculating attention mask length: 385 (current) + 1 (new) = 386\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 386])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 385, 128]), Value shape: torch.Size([1, 4, 385, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 385, 128]), Value shape: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[385], [385]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 386]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 385, 128]), Value: torch.Size([2, 4, 385, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 386, 128]), Value: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[47394], [315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 385\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its\n",
      "New token: ' sleek' (id: 47394)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 383])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15838.45MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 387])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15838.45MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.76MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.76MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 386, generated_ids shape = torch.Size([1, 383])\n",
      "Sequence 1: length = 386, generated_ids shape = torch.Size([1, 387])\n",
      "\n",
      "Found 1 different sequence lengths: [386]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 386\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[47394], [315]]\n",
      "\n",
      "Calculating attention mask length: 386 (current) + 1 (new) = 387\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 387])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 386, 128]), Value shape: torch.Size([1, 4, 386, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 386, 128]), Value shape: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[386], [386]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 387]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 386, 128]), Value: torch.Size([2, 4, 386, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 387, 128]), Value: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [9014]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 386\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 384])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15838.67MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of\n",
      "New token: ' older' (id: 9014)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 388])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15838.67MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.87MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.87MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 387, generated_ids shape = torch.Size([1, 384])\n",
      "Sequence 1: length = 387, generated_ids shape = torch.Size([1, 388])\n",
      "\n",
      "Found 1 different sequence lengths: [387]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 387\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [9014]]\n",
      "\n",
      "Calculating attention mask length: 387 (current) + 1 (new) = 388\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 388])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 387, 128]), Value shape: torch.Size([1, 4, 387, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 387, 128]), Value shape: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[387], [387]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 388]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 387, 128]), Value: torch.Size([2, 4, 387, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 388, 128]), Value: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2805], [1947]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 387\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek,\n",
      "New token: ' short' (id: 2805)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 385])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15838.89MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older\n",
      "New token: ' art' (id: 1947)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 389])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15838.89MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.98MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15795.98MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 388, generated_ids shape = torch.Size([1, 385])\n",
      "Sequence 1: length = 388, generated_ids shape = torch.Size([1, 389])\n",
      "\n",
      "Found 1 different sequence lengths: [388]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 388\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2805], [1947]]\n",
      "\n",
      "Calculating attention mask length: 388 (current) + 1 (new) = 389\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 389])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 388, 128]), Value shape: torch.Size([1, 4, 388, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 388, 128]), Value shape: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[388], [388]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 389]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 388, 128]), Value: torch.Size([2, 4, 388, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 389, 128]), Value: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3691], [67552]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 388\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short\n",
      "New token: ' black' (id: 3691)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 386])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15839.11MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art\n",
      "New token: ' deco' (id: 67552)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 390])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15839.11MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.09MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.09MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 389, generated_ids shape = torch.Size([1, 386])\n",
      "Sequence 1: length = 389, generated_ids shape = torch.Size([1, 390])\n",
      "\n",
      "Found 1 different sequence lengths: [389]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 389\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3691], [67552]]\n",
      "\n",
      "Calculating attention mask length: 389 (current) + 1 (new) = 390\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 390])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 389, 128]), Value shape: torch.Size([1, 4, 389, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 389, 128]), Value shape: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[389], [389]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 390]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 389, 128]), Value: torch.Size([2, 4, 389, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 390, 128]), Value: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[18241], [14389]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 389\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black\n",
      "New token: ' fur' (id: 18241)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 387])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15839.33MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco\n",
      "New token: ' structures' (id: 14389)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 391])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15839.33MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.21MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.21MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 390, generated_ids shape = torch.Size([1, 387])\n",
      "Sequence 1: length = 390, generated_ids shape = torch.Size([1, 391])\n",
      "\n",
      "Found 1 different sequence lengths: [390]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 390\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[18241], [14389]]\n",
      "\n",
      "Calculating attention mask length: 390 (current) + 1 (new) = 391\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 391])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 390, 128]), Value shape: torch.Size([1, 4, 390, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 390, 128]), Value shape: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[390], [390]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 391]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 390, 128]), Value: torch.Size([2, 4, 390, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 391, 128]), Value: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 390\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 388])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15839.56MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 392])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15839.56MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.32MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.32MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 391, generated_ids shape = torch.Size([1, 388])\n",
      "Sequence 1: length = 391, generated_ids shape = torch.Size([1, 392])\n",
      "\n",
      "Found 1 different sequence lengths: [391]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 391\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [323]]\n",
      "\n",
      "Calculating attention mask length: 391 (current) + 1 (new) = 392\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 392])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 391, 128]), Value shape: torch.Size([1, 4, 391, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 391, 128]), Value shape: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[391], [391]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 392]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 391, 128]), Value: torch.Size([2, 4, 391, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 392, 128]), Value: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[374], [803]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 391\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur,\n",
      "New token: ' is' (id: 374)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 389])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15839.78MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and\n",
      "New token: ' more' (id: 803)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 393])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15839.78MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.43MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.43MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 392, generated_ids shape = torch.Size([1, 389])\n",
      "Sequence 1: length = 392, generated_ids shape = torch.Size([1, 393])\n",
      "\n",
      "Found 1 different sequence lengths: [392]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 392\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[374], [803]]\n",
      "\n",
      "Calculating attention mask length: 392 (current) + 1 (new) = 393\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 393])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 392, 128]), Value shape: torch.Size([1, 4, 392, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 392, 128]), Value shape: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[392], [392]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 393]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 392, 128]), Value: torch.Size([2, 4, 392, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 393, 128]), Value: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[34228], [6481]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 392\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is\n",
      "New token: ' positioned' (id: 34228)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 390])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15840.00MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more\n",
      "New token: ' modern' (id: 6481)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 394])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15840.00MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.54MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.54MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 393, generated_ids shape = torch.Size([1, 390])\n",
      "Sequence 1: length = 393, generated_ids shape = torch.Size([1, 394])\n",
      "\n",
      "Found 1 different sequence lengths: [393]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 393\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[34228], [6481]]\n",
      "\n",
      "Calculating attention mask length: 393 (current) + 1 (new) = 394\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 394])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 393, 128]), Value shape: torch.Size([1, 4, 393, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 393, 128]), Value shape: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[393], [393]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 394]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 393, 128]), Value: torch.Size([2, 4, 393, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 394, 128]), Value: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[304], [8991]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 393\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned\n",
      "New token: ' in' (id: 304)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 391])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15840.22MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern\n",
      "New token: ' glass' (id: 8991)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 395])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15840.22MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.66MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.66MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 394, generated_ids shape = torch.Size([1, 391])\n",
      "Sequence 1: length = 394, generated_ids shape = torch.Size([1, 395])\n",
      "\n",
      "Found 1 different sequence lengths: [394]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 394\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[304], [8991]]\n",
      "\n",
      "Calculating attention mask length: 394 (current) + 1 (new) = 395\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 395])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 394, 128]), Value shape: torch.Size([1, 4, 394, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 394, 128]), Value shape: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[394], [394]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 395]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 394, 128]), Value: torch.Size([2, 4, 394, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 395, 128]), Value: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 394\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 392])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15840.44MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 396])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15840.44MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.77MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.77MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 395, generated_ids shape = torch.Size([1, 392])\n",
      "Sequence 1: length = 395, generated_ids shape = torch.Size([1, 396])\n",
      "\n",
      "Found 1 different sequence lengths: [395]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 395\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [323]]\n",
      "\n",
      "Calculating attention mask length: 395 (current) + 1 (new) = 396\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 396])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 395, 128]), Value shape: torch.Size([1, 4, 395, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 395, 128]), Value shape: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[395], [395]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 396]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 395, 128]), Value: torch.Size([2, 4, 395, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 396, 128]), Value: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[4126], [9509]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 395\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the\n",
      "New token: ' center' (id: 4126)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 393])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15840.66MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and\n",
      "New token: ' steel' (id: 9509)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 397])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15840.66MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.88MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.88MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 396, generated_ids shape = torch.Size([1, 393])\n",
      "Sequence 1: length = 396, generated_ids shape = torch.Size([1, 397])\n",
      "\n",
      "Found 1 different sequence lengths: [396]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 396\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[4126], [9509]]\n",
      "\n",
      "Calculating attention mask length: 396 (current) + 1 (new) = 397\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 397])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 396, 128]), Value shape: torch.Size([1, 4, 396, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 396, 128]), Value shape: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[396], [396]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 397]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 396, 128]), Value: torch.Size([2, 4, 396, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 397, 128]), Value: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[315], [13702]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 396\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 394])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15840.89MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel\n",
      "New token: ' buildings' (id: 13702)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 398])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15840.89MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.99MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15796.99MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 397, generated_ids shape = torch.Size([1, 394])\n",
      "Sequence 1: length = 397, generated_ids shape = torch.Size([1, 398])\n",
      "\n",
      "Found 1 different sequence lengths: [397]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 397\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[315], [13702]]\n",
      "\n",
      "Calculating attention mask length: 397 (current) + 1 (new) = 398\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 398])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 397, 128]), Value shape: torch.Size([1, 4, 397, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 397, 128]), Value shape: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[397], [397]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 398]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 397, 128]), Value: torch.Size([2, 4, 397, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 398, 128]), Value: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 397\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 395])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15841.11MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 399])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15841.11MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.11MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.11MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 398, generated_ids shape = torch.Size([1, 395])\n",
      "Sequence 1: length = 398, generated_ids shape = torch.Size([1, 399])\n",
      "\n",
      "Found 1 different sequence lengths: [398]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 398\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [11]]\n",
      "\n",
      "Calculating attention mask length: 398 (current) + 1 (new) = 399\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 399])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 398, 128]), Value shape: torch.Size([1, 4, 398, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 398, 128]), Value shape: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[398], [398]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 399]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 398, 128]), Value: torch.Size([2, 4, 398, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 399, 128]), Value: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2168], [6825]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 398\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the\n",
      "New token: ' image' (id: 2168)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 396])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15841.33MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings,\n",
      "New token: ' creating' (id: 6825)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 400])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15841.33MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.22MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.22MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 399, generated_ids shape = torch.Size([1, 396])\n",
      "Sequence 1: length = 399, generated_ids shape = torch.Size([1, 400])\n",
      "\n",
      "Found 1 different sequence lengths: [399]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 399\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2168], [6825]]\n",
      "\n",
      "Calculating attention mask length: 399 (current) + 1 (new) = 400\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 400])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 399, 128]), Value shape: torch.Size([1, 4, 399, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 399, 128]), Value shape: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[399], [399]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 400]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 399, 128]), Value: torch.Size([2, 4, 399, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 400, 128]), Value: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 399\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 397])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15841.55MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 401])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15841.55MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.33MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.33MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 400, generated_ids shape = torch.Size([1, 397])\n",
      "Sequence 1: length = 400, generated_ids shape = torch.Size([1, 401])\n",
      "\n",
      "Found 1 different sequence lengths: [400]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 400\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [264]]\n",
      "\n",
      "Calculating attention mask length: 400 (current) + 1 (new) = 401\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 401])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 400, 128]), Value shape: torch.Size([1, 4, 400, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 400, 128]), Value shape: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[400], [400]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 401]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 400, 128]), Value: torch.Size([2, 4, 400, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 401, 128]), Value: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3330], [26291]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 400\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image,\n",
      "New token: ' looking' (id: 3330)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 398])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15841.77MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a\n",
      "New token: ' fascinating' (id: 26291)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 402])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15841.77MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.44MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.44MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 401, generated_ids shape = torch.Size([1, 398])\n",
      "Sequence 1: length = 401, generated_ids shape = torch.Size([1, 402])\n",
      "\n",
      "Found 1 different sequence lengths: [401]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 401\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3330], [26291]]\n",
      "\n",
      "Calculating attention mask length: 401 (current) + 1 (new) = 402\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 402])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 401, 128]), Value shape: torch.Size([1, 4, 401, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 401, 128]), Value shape: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[401], [401]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 402]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 401, 128]), Value: torch.Size([2, 4, 401, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 402, 128]), Value: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[705], [97853]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 401\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking\n",
      "New token: ' up' (id: 705)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 399])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15842.00MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating\n",
      "New token: ' juxtap' (id: 97853)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 403])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15842.00MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.56MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.56MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 402, generated_ids shape = torch.Size([1, 399])\n",
      "Sequence 1: length = 402, generated_ids shape = torch.Size([1, 403])\n",
      "\n",
      "Found 1 different sequence lengths: [402]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 402\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[705], [97853]]\n",
      "\n",
      "Calculating attention mask length: 402 (current) + 1 (new) = 403\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 403])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 402, 128]), Value shape: torch.Size([1, 4, 402, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 402, 128]), Value shape: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[402], [402]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 403]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 402, 128]), Value: torch.Size([2, 4, 402, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 403, 128]), Value: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[518], [2113]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 402\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up\n",
      "New token: ' at' (id: 518)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 400])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15842.22MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtap\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtap\n",
      "New token: 'osition' (id: 2113)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 404])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15842.22MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.67MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.67MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 403, generated_ids shape = torch.Size([1, 400])\n",
      "Sequence 1: length = 403, generated_ids shape = torch.Size([1, 404])\n",
      "\n",
      "Found 1 different sequence lengths: [403]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 403\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[518], [2113]]\n",
      "\n",
      "Calculating attention mask length: 403 (current) + 1 (new) = 404\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 404])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 403, 128]), Value shape: torch.Size([1, 4, 403, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 403, 128]), Value shape: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[403], [403]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 404]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 403, 128]), Value: torch.Size([2, 4, 403, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 404, 128]), Value: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 403\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 401])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15842.44MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 405])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15842.44MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.78MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.78MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 404, generated_ids shape = torch.Size([1, 401])\n",
      "Sequence 1: length = 404, generated_ids shape = torch.Size([1, 405])\n",
      "\n",
      "Found 1 different sequence lengths: [404]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 404\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [315]]\n",
      "\n",
      "Calculating attention mask length: 404 (current) + 1 (new) = 405\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 405])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 404, 128]), Value shape: torch.Size([1, 4, 404, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 404, 128]), Value shape: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[404], [404]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 405]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 404, 128]), Value: torch.Size([2, 4, 404, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 405, 128]), Value: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[6249], [42463]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 404\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the\n",
      "New token: ' camera' (id: 6249)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 402])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15842.66MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of\n",
      "New token: ' architectural' (id: 42463)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 406])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15842.66MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.89MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15797.89MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 405, generated_ids shape = torch.Size([1, 402])\n",
      "Sequence 1: length = 405, generated_ids shape = torch.Size([1, 406])\n",
      "\n",
      "Found 1 different sequence lengths: [405]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 405\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[6249], [42463]]\n",
      "\n",
      "Calculating attention mask length: 405 (current) + 1 (new) = 406\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 406])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 405, 128]), Value shape: torch.Size([1, 4, 405, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 405, 128]), Value shape: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[405], [405]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 406]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 405, 128]), Value: torch.Size([2, 4, 405, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 406, 128]), Value: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[448], [2714]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 405\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera\n",
      "New token: ' with' (id: 448)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 403])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15842.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural\n",
      "New token: ' er' (id: 2714)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 407])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15842.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.00MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.00MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 406, generated_ids shape = torch.Size([1, 403])\n",
      "Sequence 1: length = 406, generated_ids shape = torch.Size([1, 407])\n",
      "\n",
      "Found 1 different sequence lengths: [406]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 406\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[448], [2714]]\n",
      "\n",
      "Calculating attention mask length: 406 (current) + 1 (new) = 407\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 407])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 406, 128]), Value shape: torch.Size([1, 4, 406, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 406, 128]), Value shape: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[406], [406]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 407]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 406, 128]), Value: torch.Size([2, 4, 406, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 407, 128]), Value: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [300]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 406\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 404])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15843.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural er\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural er\n",
      "New token: 'as' (id: 300)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 408])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15843.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.12MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.12MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 407, generated_ids shape = torch.Size([1, 404])\n",
      "Sequence 1: length = 407, generated_ids shape = torch.Size([1, 408])\n",
      "\n",
      "Found 1 different sequence lengths: [407]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 407\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [300]]\n",
      "\n",
      "Calculating attention mask length: 407 (current) + 1 (new) = 408\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 408])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 407, 128]), Value shape: torch.Size([1, 4, 407, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 407, 128]), Value shape: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[407], [407]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 408]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 407, 128]), Value: torch.Size([2, 4, 407, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 408, 128]), Value: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[77123], [13]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 407\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its\n",
      "New token: ' expressive' (id: 77123)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 405])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15843.33MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 409])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15843.33MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.23MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.23MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 408, generated_ids shape = torch.Size([1, 405])\n",
      "Sequence 1: length = 408, generated_ids shape = torch.Size([1, 409])\n",
      "\n",
      "Found 1 different sequence lengths: [408]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 408\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[77123], [13]]\n",
      "\n",
      "Calculating attention mask length: 408 (current) + 1 (new) = 409\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 409])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 408, 128]), Value shape: torch.Size([1, 4, 408, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 408, 128]), Value shape: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[408], [408]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 409]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 408, 128]), Value: torch.Size([2, 4, 408, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 409, 128]), Value: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13876], [576]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 408\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive\n",
      "New token: ' brown' (id: 13876)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 406])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15843.55MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras.\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 410])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15843.55MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.34MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.34MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 409, generated_ids shape = torch.Size([1, 406])\n",
      "Sequence 1: length = 409, generated_ids shape = torch.Size([1, 410])\n",
      "\n",
      "Found 1 different sequence lengths: [409]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 409\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13876], [576]]\n",
      "\n",
      "Calculating attention mask length: 409 (current) + 1 (new) = 410\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 410])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 409, 128]), Value shape: torch.Size([1, 4, 409, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 409, 128]), Value shape: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[409], [409]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 410]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 409, 128]), Value: torch.Size([2, 4, 409, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 410, 128]), Value: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[6414], [13702]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 409\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown\n",
      "New token: ' eyes' (id: 6414)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 407])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15843.77MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The\n",
      "New token: ' buildings' (id: 13702)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 411])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15843.77MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.46MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.46MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 410, generated_ids shape = torch.Size([1, 407])\n",
      "Sequence 1: length = 410, generated_ids shape = torch.Size([1, 411])\n",
      "\n",
      "Found 1 different sequence lengths: [410]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 410\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[6414], [13702]]\n",
      "\n",
      "Calculating attention mask length: 410 (current) + 1 (new) = 411\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 411])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 410, 128]), Value shape: torch.Size([1, 4, 410, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 410, 128]), Value shape: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[410], [410]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 411]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 410, 128]), Value: torch.Size([2, 4, 410, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 411, 128]), Value: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [525]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 410\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 408])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15843.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings\n",
      "New token: ' are' (id: 525)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 412])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15843.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.57MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.57MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 411, generated_ids shape = torch.Size([1, 408])\n",
      "Sequence 1: length = 411, generated_ids shape = torch.Size([1, 412])\n",
      "\n",
      "Found 1 different sequence lengths: [411]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 411\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [525]]\n",
      "\n",
      "Calculating attention mask length: 411 (current) + 1 (new) = 412\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 412])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 411, 128]), Value shape: torch.Size([1, 4, 411, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 411, 128]), Value shape: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[411], [411]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 412]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 411, 128]), Value: torch.Size([2, 4, 411, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 412, 128]), Value: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11445], [38969]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 411\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes.\n",
      "New token: ' Its' (id: 11445)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 409])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15844.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are\n",
      "New token: ' tightly' (id: 38969)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 413])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15844.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.68MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.68MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 412, generated_ids shape = torch.Size([1, 409])\n",
      "Sequence 1: length = 412, generated_ids shape = torch.Size([1, 413])\n",
      "\n",
      "Found 1 different sequence lengths: [412]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 412\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11445], [38969]]\n",
      "\n",
      "Calculating attention mask length: 412 (current) + 1 (new) = 413\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 413])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 412, 128]), Value shape: torch.Size([1, 4, 412, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 412, 128]), Value shape: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[412], [412]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 413]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 412, 128]), Value: torch.Size([2, 4, 412, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 413, 128]), Value: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[24230], [19375]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 412\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its\n",
      "New token: ' ears' (id: 24230)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 410])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15844.44MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly\n",
      "New token: ' packed' (id: 19375)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 414])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15844.44MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.79MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.79MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 413, generated_ids shape = torch.Size([1, 410])\n",
      "Sequence 1: length = 413, generated_ids shape = torch.Size([1, 414])\n",
      "\n",
      "Found 1 different sequence lengths: [413]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 413\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[24230], [19375]]\n",
      "\n",
      "Calculating attention mask length: 413 (current) + 1 (new) = 414\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 414])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 413, 128]), Value shape: torch.Size([1, 4, 413, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 413, 128]), Value shape: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[413], [413]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 414]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 413, 128]), Value: torch.Size([2, 4, 413, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 414, 128]), Value: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[525], [3786]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 413\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears\n",
      "New token: ' are' (id: 525)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 411])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15844.66MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed\n",
      "New token: ' together' (id: 3786)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 415])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15844.66MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.91MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15798.91MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 414, generated_ids shape = torch.Size([1, 411])\n",
      "Sequence 1: length = 414, generated_ids shape = torch.Size([1, 415])\n",
      "\n",
      "Found 1 different sequence lengths: [414]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 414\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[525], [3786]]\n",
      "\n",
      "Calculating attention mask length: 414 (current) + 1 (new) = 415\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 415])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 414, 128]), Value shape: torch.Size([1, 4, 414, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 414, 128]), Value shape: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[414], [414]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 415]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 414, 128]), Value: torch.Size([2, 4, 414, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 415, 128]), Value: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[10078], [11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 414\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are\n",
      "New token: ' slightly' (id: 10078)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 412])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15844.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 416])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15844.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.02MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.02MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 415, generated_ids shape = torch.Size([1, 412])\n",
      "Sequence 1: length = 415, generated_ids shape = torch.Size([1, 416])\n",
      "\n",
      "Found 1 different sequence lengths: [415]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 415\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[10078], [11]]\n",
      "\n",
      "Calculating attention mask length: 415 (current) + 1 (new) = 416\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 416])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 415, 128]), Value shape: torch.Size([1, 4, 415, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 415, 128]), Value shape: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[415], [415]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 416]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 415, 128]), Value: torch.Size([2, 4, 415, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 416, 128]), Value: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[91358], [29064]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 415\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly\n",
      "New token: ' floppy' (id: 91358)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 413])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15845.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together,\n",
      "New token: ' forming' (id: 29064)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 417])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15845.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.13MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.13MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 416, generated_ids shape = torch.Size([1, 413])\n",
      "Sequence 1: length = 416, generated_ids shape = torch.Size([1, 417])\n",
      "\n",
      "Found 1 different sequence lengths: [416]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 416\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[91358], [29064]]\n",
      "\n",
      "Calculating attention mask length: 416 (current) + 1 (new) = 417\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 417])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 416, 128]), Value shape: torch.Size([1, 4, 416, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 416, 128]), Value shape: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[416], [416]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 417]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 416, 128]), Value: torch.Size([2, 4, 416, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 417, 128]), Value: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 416\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 414])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15845.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 418])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15845.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.24MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.24MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 417, generated_ids shape = torch.Size([1, 414])\n",
      "Sequence 1: length = 417, generated_ids shape = torch.Size([1, 418])\n",
      "\n",
      "Found 1 different sequence lengths: [417]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 417\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [264]]\n",
      "\n",
      "Calculating attention mask length: 417 (current) + 1 (new) = 418\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 418])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 417, 128]), Value shape: torch.Size([1, 4, 417, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 417, 128]), Value shape: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[417], [417]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 418]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 417, 128]), Value: torch.Size([2, 4, 417, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 418, 128]), Value: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[323], [6351]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 417\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy,\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 415])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15845.55MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a\n",
      "New token: ' complex' (id: 6351)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 419])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15845.55MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.36MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.36MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 418, generated_ids shape = torch.Size([1, 415])\n",
      "Sequence 1: length = 418, generated_ids shape = torch.Size([1, 419])\n",
      "\n",
      "Found 1 different sequence lengths: [418]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 418\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[323], [6351]]\n",
      "\n",
      "Calculating attention mask length: 418 (current) + 1 (new) = 419\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 419])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 418, 128]), Value shape: torch.Size([1, 4, 418, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 418, 128]), Value shape: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[418], [418]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 419]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 418, 128]), Value: torch.Size([2, 4, 418, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 419, 128]), Value: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 418\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 416])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15845.77MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 420])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15845.77MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.47MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.47MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 419, generated_ids shape = torch.Size([1, 416])\n",
      "Sequence 1: length = 419, generated_ids shape = torch.Size([1, 420])\n",
      "\n",
      "Found 1 different sequence lengths: [419]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 419\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [323]]\n",
      "\n",
      "Calculating attention mask length: 419 (current) + 1 (new) = 420\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 420])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 419, 128]), Value shape: torch.Size([1, 4, 419, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 419, 128]), Value shape: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[419], [419]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 420]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 419, 128]), Value: torch.Size([2, 4, 419, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 420, 128]), Value: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9787], [56116]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 419\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its\n",
      "New token: ' tail' (id: 9787)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 417])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15845.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and\n",
      "New token: ' intricate' (id: 56116)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 421])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15845.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.58MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.58MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 420, generated_ids shape = torch.Size([1, 417])\n",
      "Sequence 1: length = 420, generated_ids shape = torch.Size([1, 421])\n",
      "\n",
      "Found 1 different sequence lengths: [420]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 420\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9787], [56116]]\n",
      "\n",
      "Calculating attention mask length: 420 (current) + 1 (new) = 421\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 421])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 420, 128]), Value shape: torch.Size([1, 4, 420, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 420, 128]), Value shape: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[420], [420]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 421]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 420, 128]), Value: torch.Size([2, 4, 420, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 421, 128]), Value: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[374], [3283]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 420\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail\n",
      "New token: ' is' (id: 374)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 418])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15846.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate\n",
      "New token: ' city' (id: 3283)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 422])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15846.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.69MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.69MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 421, generated_ids shape = torch.Size([1, 418])\n",
      "Sequence 1: length = 421, generated_ids shape = torch.Size([1, 422])\n",
      "\n",
      "Found 1 different sequence lengths: [421]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 421\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[374], [3283]]\n",
      "\n",
      "Calculating attention mask length: 421 (current) + 1 (new) = 422\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 422])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 421, 128]), Value shape: torch.Size([1, 4, 421, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 421, 128]), Value shape: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[421], [421]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 422]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 421, 128]), Value: torch.Size([2, 4, 421, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 422, 128]), Value: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[817], [57518]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 421\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is\n",
      "New token: ' per' (id: 817)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 419])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15846.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate city\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate city\n",
      "New token: 'scape' (id: 57518)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 423])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15846.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.81MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.81MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 422, generated_ids shape = torch.Size([1, 419])\n",
      "Sequence 1: length = 422, generated_ids shape = torch.Size([1, 423])\n",
      "\n",
      "Found 1 different sequence lengths: [422]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 422\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[817], [57518]]\n",
      "\n",
      "Calculating attention mask length: 422 (current) + 1 (new) = 423\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 423])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 422, 128]), Value shape: torch.Size([1, 4, 422, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 422, 128]), Value shape: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[422], [422]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 423]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 422, 128]), Value: torch.Size([2, 4, 422, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 423, 128]), Value: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[47159], [429]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 422\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is per\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is per\n",
      "New token: 'ked' (id: 47159)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 420])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15846.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape\n",
      "New token: ' that' (id: 429)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 424])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15846.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.92MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15799.92MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 423, generated_ids shape = torch.Size([1, 420])\n",
      "Sequence 1: length = 423, generated_ids shape = torch.Size([1, 424])\n",
      "\n",
      "Found 1 different sequence lengths: [423]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 423\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[47159], [429]]\n",
      "\n",
      "Calculating attention mask length: 423 (current) + 1 (new) = 424\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 424])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 423, 128]), Value shape: torch.Size([1, 4, 423, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 423, 128]), Value shape: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[423], [423]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 424]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 423, 128]), Value: torch.Size([2, 4, 423, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 424, 128]), Value: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[705], [49599]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 423\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked\n",
      "New token: ' up' (id: 705)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 421])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15846.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that\n",
      "New token: ' stretches' (id: 49599)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 425])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15846.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.03MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.03MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 424, generated_ids shape = torch.Size([1, 421])\n",
      "Sequence 1: length = 424, generated_ids shape = torch.Size([1, 425])\n",
      "\n",
      "Found 1 different sequence lengths: [424]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 424\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[705], [49599]]\n",
      "\n",
      "Calculating attention mask length: 424 (current) + 1 (new) = 425\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 425])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 424, 128]), Value shape: torch.Size([1, 4, 424, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 424, 128]), Value shape: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[424], [424]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 425]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 424, 128]), Value: torch.Size([2, 4, 424, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 425, 128]), Value: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [438]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 424\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 422])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15847.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches\n",
      "New token: ' as' (id: 438)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 426])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15847.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.14MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.14MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 425, generated_ids shape = torch.Size([1, 422])\n",
      "Sequence 1: length = 425, generated_ids shape = torch.Size([1, 426])\n",
      "\n",
      "Found 1 different sequence lengths: [425]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 425\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [438]]\n",
      "\n",
      "Calculating attention mask length: 425 (current) + 1 (new) = 426\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 426])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 425, 128]), Value shape: torch.Size([1, 4, 425, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 425, 128]), Value shape: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[425], [425]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 426]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 425, 128]), Value: torch.Size([2, 4, 425, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 426, 128]), Value: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[7842], [3041]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 425\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up,\n",
      "New token: ' adding' (id: 7842)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 423])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15847.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as\n",
      "New token: ' far' (id: 3041)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 427])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15847.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.26MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.26MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 426, generated_ids shape = torch.Size([1, 423])\n",
      "Sequence 1: length = 426, generated_ids shape = torch.Size([1, 427])\n",
      "\n",
      "Found 1 different sequence lengths: [426]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 426\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[7842], [3041]]\n",
      "\n",
      "Calculating attention mask length: 426 (current) + 1 (new) = 427\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 427])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 426, 128]), Value shape: torch.Size([1, 4, 426, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 426, 128]), Value shape: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[426], [426]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 427]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 426, 128]), Value: torch.Size([2, 4, 426, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 427, 128]), Value: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[311], [438]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 426\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding\n",
      "New token: ' to' (id: 311)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 424])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15847.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far\n",
      "New token: ' as' (id: 438)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 428])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15847.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.37MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.37MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 427, generated_ids shape = torch.Size([1, 424])\n",
      "Sequence 1: length = 427, generated_ids shape = torch.Size([1, 428])\n",
      "\n",
      "Found 1 different sequence lengths: [427]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 427\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[311], [438]]\n",
      "\n",
      "Calculating attention mask length: 427 (current) + 1 (new) = 428\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 428])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 427, 128]), Value shape: torch.Size([1, 4, 427, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 427, 128]), Value shape: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[427], [427]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 428]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 427, 128]), Value: torch.Size([2, 4, 427, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 428, 128]), Value: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 427\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 425])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15847.77MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 429])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15847.77MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.48MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.48MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 428, generated_ids shape = torch.Size([1, 425])\n",
      "Sequence 1: length = 428, generated_ids shape = torch.Size([1, 429])\n",
      "\n",
      "Found 1 different sequence lengths: [428]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 428\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [279]]\n",
      "\n",
      "Calculating attention mask length: 428 (current) + 1 (new) = 429\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 429])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 428, 128]), Value shape: torch.Size([1, 4, 428, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 428, 128]), Value shape: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[428], [428]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 429]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 428, 128]), Value: torch.Size([2, 4, 428, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 429, 128]), Value: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[72798], [7912]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 428\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its\n",
      "New token: ' attentive' (id: 72798)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 426])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15847.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the\n",
      "New token: ' eye' (id: 7912)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 430])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15847.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.59MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.59MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 429, generated_ids shape = torch.Size([1, 426])\n",
      "Sequence 1: length = 429, generated_ids shape = torch.Size([1, 430])\n",
      "\n",
      "Found 1 different sequence lengths: [429]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 429\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[72798], [7912]]\n",
      "\n",
      "Calculating attention mask length: 429 (current) + 1 (new) = 430\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 430])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 429, 128]), Value shape: torch.Size([1, 4, 429, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 429, 128]), Value shape: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[429], [429]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 430]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 429, 128]), Value: torch.Size([2, 4, 429, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 430, 128]), Value: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[323], [646]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 429\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 427])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15848.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye\n",
      "New token: ' can' (id: 646)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 431])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15848.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.71MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.71MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 430, generated_ids shape = torch.Size([1, 427])\n",
      "Sequence 1: length = 430, generated_ids shape = torch.Size([1, 431])\n",
      "\n",
      "Found 1 different sequence lengths: [430]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 430\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[323], [646]]\n",
      "\n",
      "Calculating attention mask length: 430 (current) + 1 (new) = 431\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 431])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 430, 128]), Value shape: torch.Size([1, 4, 430, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 430, 128]), Value shape: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[430], [430]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 431]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 430, 128]), Value: torch.Size([2, 4, 430, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 431, 128]), Value: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[22208], [1490]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 430\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and\n",
      "New token: ' curious' (id: 22208)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 428])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15848.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can\n",
      "New token: ' see' (id: 1490)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 432])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15848.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.82MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.82MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 431, generated_ids shape = torch.Size([1, 428])\n",
      "Sequence 1: length = 431, generated_ids shape = torch.Size([1, 432])\n",
      "\n",
      "Found 1 different sequence lengths: [431]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 431\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[22208], [1490]]\n",
      "\n",
      "Calculating attention mask length: 431 (current) + 1 (new) = 432\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 432])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 431, 128]), Value shape: torch.Size([1, 4, 431, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 431, 128]), Value shape: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[431], [431]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 432]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 431, 128]), Value: torch.Size([2, 4, 431, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 432, 128]), Value: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[93015], [382]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 431\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious\n",
      "New token: ' demeanor' (id: 93015)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 429])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15848.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see\n",
      "New token: '.\n",
      "\n",
      "' (id: 382)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 433])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15848.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.93MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15800.93MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 432, generated_ids shape = torch.Size([1, 429])\n",
      "Sequence 1: length = 432, generated_ids shape = torch.Size([1, 433])\n",
      "\n",
      "Found 1 different sequence lengths: [432]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 432\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[93015], [382]]\n",
      "\n",
      "Calculating attention mask length: 432 (current) + 1 (new) = 433\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 433])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 432, 128]), Value shape: torch.Size([1, 4, 432, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 432, 128]), Value shape: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[432], [432]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 433]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 432, 128]), Value: torch.Size([2, 4, 432, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 433, 128]), Value: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [785]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 432\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 430])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15848.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "\n",
      "New token: 'The' (id: 785)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 434])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15848.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.04MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.04MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 433, generated_ids shape = torch.Size([1, 430])\n",
      "Sequence 1: length = 433, generated_ids shape = torch.Size([1, 434])\n",
      "\n",
      "Found 1 different sequence lengths: [433]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 433\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [785]]\n",
      "\n",
      "Calculating attention mask length: 433 (current) + 1 (new) = 434\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 434])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 433, 128]), Value shape: torch.Size([1, 4, 433, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 433, 128]), Value shape: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[433], [433]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 434]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 433, 128]), Value: torch.Size([2, 4, 433, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 434, 128]), Value: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[576], [12884]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 433\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 431])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15849.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The\n",
      "New token: ' sky' (id: 12884)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 435])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15849.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.16MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.16MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 434, generated_ids shape = torch.Size([1, 431])\n",
      "Sequence 1: length = 434, generated_ids shape = torch.Size([1, 435])\n",
      "\n",
      "Found 1 different sequence lengths: [434]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 434\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[576], [12884]]\n",
      "\n",
      "Calculating attention mask length: 434 (current) + 1 (new) = 435\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 435])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 434, 128]), Value shape: torch.Size([1, 4, 434, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 434, 128]), Value shape: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[434], [434]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 435]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 434, 128]), Value: torch.Size([2, 4, 434, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 435, 128]), Value: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[41189], [7952]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 434\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The\n",
      "New token: ' puppy' (id: 41189)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 432])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15849.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky\n",
      "New token: ' appears' (id: 7952)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 436])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15849.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.27MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.27MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 435, generated_ids shape = torch.Size([1, 432])\n",
      "Sequence 1: length = 435, generated_ids shape = torch.Size([1, 436])\n",
      "\n",
      "Found 1 different sequence lengths: [435]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 435\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[41189], [7952]]\n",
      "\n",
      "Calculating attention mask length: 435 (current) + 1 (new) = 436\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 436])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 435, 128]), Value shape: torch.Size([1, 4, 435, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 435, 128]), Value shape: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[435], [435]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 436]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 435, 128]), Value: torch.Size([2, 4, 435, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 436, 128]), Value: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[594], [916]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 435\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy\n",
      "New token: ''s' (id: 594)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 433])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15849.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears\n",
      "New token: ' over' (id: 916)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 437])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15849.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.38MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.38MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 436, generated_ids shape = torch.Size([1, 433])\n",
      "Sequence 1: length = 436, generated_ids shape = torch.Size([1, 437])\n",
      "\n",
      "Found 1 different sequence lengths: [436]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 436\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[594], [916]]\n",
      "\n",
      "Calculating attention mask length: 436 (current) + 1 (new) = 437\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 437])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 436, 128]), Value shape: torch.Size([1, 4, 436, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 436, 128]), Value shape: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[436], [436]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 437]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 436, 128]), Value: torch.Size([2, 4, 436, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 437, 128]), Value: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[4065], [3829]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 436\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's\n",
      "New token: ' front' (id: 4065)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 434])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15849.76MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears over\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears over\n",
      "New token: 'cast' (id: 3829)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 438])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15849.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.50MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.50MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 437, generated_ids shape = torch.Size([1, 434])\n",
      "Sequence 1: length = 437, generated_ids shape = torch.Size([1, 438])\n",
      "\n",
      "Found 1 different sequence lengths: [437]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 437\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[4065], [3829]]\n",
      "\n",
      "Calculating attention mask length: 437 (current) + 1 (new) = 438\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 438])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 437, 128]), Value shape: torch.Size([1, 4, 437, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 437, 128]), Value shape: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[437], [437]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 438]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 437, 128]), Value: torch.Size([2, 4, 437, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 438, 128]), Value: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[281], [448]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 437\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front\n",
      "New token: ' p' (id: 281)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 435])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15849.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast\n",
      "New token: ' with' (id: 448)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 439])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15849.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.61MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.61MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 438, generated_ids shape = torch.Size([1, 435])\n",
      "Sequence 1: length = 438, generated_ids shape = torch.Size([1, 439])\n",
      "\n",
      "Found 1 different sequence lengths: [438]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 438\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[281], [448]]\n",
      "\n",
      "Calculating attention mask length: 438 (current) + 1 (new) = 439\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 439])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 438, 128]), Value shape: torch.Size([1, 4, 438, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 438, 128]), Value shape: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[438], [438]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 439]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 438, 128]), Value: torch.Size([2, 4, 438, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 439, 128]), Value: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[8635], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 438\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front p\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front p\n",
      "New token: 'aws' (id: 8635)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 436])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15850.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 440])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15850.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.72MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.72MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 439, generated_ids shape = torch.Size([1, 436])\n",
      "Sequence 1: length = 439, generated_ids shape = torch.Size([1, 440])\n",
      "\n",
      "Found 1 different sequence lengths: [439]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 439\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[8635], [264]]\n",
      "\n",
      "Calculating attention mask length: 439 (current) + 1 (new) = 440\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 440])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 439, 128]), Value shape: torch.Size([1, 4, 439, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 439, 128]), Value shape: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[439], [439]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 440]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 439, 128]), Value: torch.Size([2, 4, 439, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 440, 128]), Value: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[525], [20169]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 439\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws\n",
      "New token: ' are' (id: 525)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 437])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15850.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a\n",
      "New token: ' gradient' (id: 20169)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 441])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15850.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.83MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.83MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 440, generated_ids shape = torch.Size([1, 437])\n",
      "Sequence 1: length = 440, generated_ids shape = torch.Size([1, 441])\n",
      "\n",
      "Found 1 different sequence lengths: [440]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 440\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[525], [20169]]\n",
      "\n",
      "Calculating attention mask length: 440 (current) + 1 (new) = 441\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 441])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 440, 128]), Value shape: torch.Size([1, 4, 440, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 440, 128]), Value shape: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[440], [440]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 441]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 440, 128]), Value: torch.Size([2, 4, 440, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 441, 128]), Value: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[9434], [504]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 440\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are\n",
      "New token: ' visible' (id: 9434)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 438])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15850.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient\n",
      "New token: ' from' (id: 504)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 442])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15850.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.95MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15801.95MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 441, generated_ids shape = torch.Size([1, 438])\n",
      "Sequence 1: length = 441, generated_ids shape = torch.Size([1, 442])\n",
      "\n",
      "Found 1 different sequence lengths: [441]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 441\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[9434], [504]]\n",
      "\n",
      "Calculating attention mask length: 441 (current) + 1 (new) = 442\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 442])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 441, 128]), Value shape: torch.Size([1, 4, 441, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 441, 128]), Value shape: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[441], [441]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 442]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 441, 128]), Value: torch.Size([2, 4, 441, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 442, 128]), Value: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [39030]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 441\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 439])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15850.87MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from\n",
      "New token: ' darker' (id: 39030)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 443])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15850.87MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.06MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.06MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 442, generated_ids shape = torch.Size([1, 439])\n",
      "Sequence 1: length = 442, generated_ids shape = torch.Size([1, 443])\n",
      "\n",
      "Found 1 different sequence lengths: [442]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 442\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [39030]]\n",
      "\n",
      "Calculating attention mask length: 442 (current) + 1 (new) = 443\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 443])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 442, 128]), Value shape: torch.Size([1, 4, 442, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 442, 128]), Value shape: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[442], [442]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 443]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 442, 128]), Value: torch.Size([2, 4, 442, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 443, 128]), Value: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1393], [29514]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 442\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible,\n",
      "New token: ' while' (id: 1393)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 440])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15851.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker\n",
      "New token: ' clouds' (id: 29514)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 444])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15851.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.17MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.17MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 443, generated_ids shape = torch.Size([1, 440])\n",
      "Sequence 1: length = 443, generated_ids shape = torch.Size([1, 444])\n",
      "\n",
      "Found 1 different sequence lengths: [443]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 443\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1393], [29514]]\n",
      "\n",
      "Calculating attention mask length: 443 (current) + 1 (new) = 444\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 444])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 443, 128]), Value shape: torch.Size([1, 4, 443, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 443, 128]), Value shape: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[443], [443]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 444]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 443, 128]), Value: torch.Size([2, 4, 443, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 444, 128]), Value: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [518]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 443\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 441])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15851.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds\n",
      "New token: ' at' (id: 518)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 445])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15851.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.28MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.28MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 444, generated_ids shape = torch.Size([1, 441])\n",
      "Sequence 1: length = 444, generated_ids shape = torch.Size([1, 445])\n",
      "\n",
      "Found 1 different sequence lengths: [444]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 444\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [518]]\n",
      "\n",
      "Calculating attention mask length: 444 (current) + 1 (new) = 445\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 445])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 444, 128]), Value shape: torch.Size([1, 4, 444, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 444, 128]), Value shape: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[444], [444]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 445]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 444, 128]), Value: torch.Size([2, 4, 444, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 445, 128]), Value: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1182], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 444\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its\n",
      "New token: ' back' (id: 1182)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 442])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15851.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 446])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15851.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.40MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.40MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 445, generated_ids shape = torch.Size([1, 442])\n",
      "Sequence 1: length = 445, generated_ids shape = torch.Size([1, 446])\n",
      "\n",
      "Found 1 different sequence lengths: [445]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 445\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1182], [279]]\n",
      "\n",
      "Calculating attention mask length: 445 (current) + 1 (new) = 446\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 446])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 445, 128]), Value shape: torch.Size([1, 4, 445, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 445, 128]), Value shape: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[445], [445]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 446]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 445, 128]), Value: torch.Size([2, 4, 445, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 446, 128]), Value: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[281], [1909]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 445\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back\n",
      "New token: ' p' (id: 281)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 443])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15851.76MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the\n",
      "New token: ' top' (id: 1909)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 447])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15851.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.51MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.51MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 446, generated_ids shape = torch.Size([1, 443])\n",
      "Sequence 1: length = 446, generated_ids shape = torch.Size([1, 447])\n",
      "\n",
      "Found 1 different sequence lengths: [446]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 446\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[281], [1909]]\n",
      "\n",
      "Calculating attention mask length: 446 (current) + 1 (new) = 447\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 447])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 446, 128]), Value shape: torch.Size([1, 4, 446, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 446, 128]), Value shape: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[446], [446]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 447]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 446, 128]), Value: torch.Size([2, 4, 446, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 447, 128]), Value: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[8635], [311]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 446\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back p\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back p\n",
      "New token: 'aws' (id: 8635)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 444])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15851.98MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top\n",
      "New token: ' to' (id: 311)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 448])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15851.98MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.62MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.62MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 447, generated_ids shape = torch.Size([1, 444])\n",
      "Sequence 1: length = 447, generated_ids shape = torch.Size([1, 448])\n",
      "\n",
      "Found 1 different sequence lengths: [447]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 447\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[8635], [311]]\n",
      "\n",
      "Calculating attention mask length: 447 (current) + 1 (new) = 448\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 448])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 447, 128]), Value shape: torch.Size([1, 4, 447, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 447, 128]), Value shape: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[447], [447]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 448]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 447, 128]), Value: torch.Size([2, 4, 447, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 448, 128]), Value: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[525], [29573]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 447\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws\n",
      "New token: ' are' (id: 525)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 445])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15852.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to\n",
      "New token: ' lighter' (id: 29573)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 449])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15852.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.74MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.74MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 448, generated_ids shape = torch.Size([1, 445])\n",
      "Sequence 1: length = 448, generated_ids shape = torch.Size([1, 449])\n",
      "\n",
      "Found 1 different sequence lengths: [448]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 448\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[525], [29573]]\n",
      "\n",
      "Calculating attention mask length: 448 (current) + 1 (new) = 449\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 449])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 448, 128]), Value shape: torch.Size([1, 4, 448, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 448, 128]), Value shape: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[448], [448]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 449]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 448, 128]), Value: torch.Size([2, 4, 448, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 449, 128]), Value: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[60118], [5671]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 448\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are\n",
      "New token: ' tucked' (id: 60118)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 446])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15852.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter\n",
      "New token: ' areas' (id: 5671)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 450])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15852.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.85MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.85MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 449, generated_ids shape = torch.Size([1, 446])\n",
      "Sequence 1: length = 449, generated_ids shape = torch.Size([1, 450])\n",
      "\n",
      "Found 1 different sequence lengths: [449]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 449\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[60118], [5671]]\n",
      "\n",
      "Calculating attention mask length: 449 (current) + 1 (new) = 450\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 450])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 449, 128]), Value shape: torch.Size([1, 4, 449, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 449, 128]), Value shape: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[449], [449]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 450]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 449, 128]), Value: torch.Size([2, 4, 449, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 450, 128]), Value: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[29356], [3143]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 449\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked\n",
      "New token: ' underneath' (id: 29356)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 447])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15852.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas\n",
      "New token: ' near' (id: 3143)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 451])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15852.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.96MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15802.96MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 450, generated_ids shape = torch.Size([1, 447])\n",
      "Sequence 1: length = 450, generated_ids shape = torch.Size([1, 451])\n",
      "\n",
      "Found 1 different sequence lengths: [450]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 450\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[29356], [3143]]\n",
      "\n",
      "Calculating attention mask length: 450 (current) + 1 (new) = 451\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 451])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 450, 128]), Value shape: torch.Size([1, 4, 450, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 450, 128]), Value shape: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[450], [450]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 451]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 450, 128]), Value: torch.Size([2, 4, 450, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 451, 128]), Value: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[1181], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 450\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 448])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15852.87MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 452])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15852.87MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.07MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.07MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 451, generated_ids shape = torch.Size([1, 448])\n",
      "Sequence 1: length = 451, generated_ids shape = torch.Size([1, 452])\n",
      "\n",
      "Found 1 different sequence lengths: [451]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 451\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[1181], [279]]\n",
      "\n",
      "Calculating attention mask length: 451 (current) + 1 (new) = 452\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 452])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 451, 128]), Value shape: torch.Size([1, 4, 451, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 451, 128]), Value shape: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[451], [451]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 452]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 451, 128]), Value: torch.Size([2, 4, 451, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 452, 128]), Value: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2487], [34074]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 451\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its\n",
      "New token: ' body' (id: 2487)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 449])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15853.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the\n",
      "New token: ' horizon' (id: 34074)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 453])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15853.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.19MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.19MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 452, generated_ids shape = torch.Size([1, 449])\n",
      "Sequence 1: length = 452, generated_ids shape = torch.Size([1, 453])\n",
      "\n",
      "Found 1 different sequence lengths: [452]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 452\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2487], [34074]]\n",
      "\n",
      "Calculating attention mask length: 452 (current) + 1 (new) = 453\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 453])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 452, 128]), Value shape: torch.Size([1, 4, 452, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 452, 128]), Value shape: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[452], [452]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 453]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 452, 128]), Value: torch.Size([2, 4, 452, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 453, 128]), Value: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 452\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 450])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15853.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 454])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15853.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.30MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.30MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 453, generated_ids shape = torch.Size([1, 450])\n",
      "Sequence 1: length = 453, generated_ids shape = torch.Size([1, 454])\n",
      "\n",
      "Found 1 different sequence lengths: [453]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 453\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [11]]\n",
      "\n",
      "Calculating attention mask length: 453 (current) + 1 (new) = 454\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 454])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 453, 128]), Value shape: torch.Size([1, 4, 453, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 453, 128]), Value shape: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[453], [453]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 454]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 453, 128]), Value: torch.Size([2, 4, 453, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 454, 128]), Value: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[576], [22561]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 453\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body.\n",
      "New token: ' The' (id: 576)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 451])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15853.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon,\n",
      "New token: ' suggesting' (id: 22561)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 455])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15853.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.41MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.41MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 454, generated_ids shape = torch.Size([1, 451])\n",
      "Sequence 1: length = 454, generated_ids shape = torch.Size([1, 455])\n",
      "\n",
      "Found 1 different sequence lengths: [454]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 454\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[576], [22561]]\n",
      "\n",
      "Calculating attention mask length: 454 (current) + 1 (new) = 455\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 455])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 454, 128]), Value shape: torch.Size([1, 4, 454, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 454, 128]), Value shape: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[454], [454]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 455]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 454, 128]), Value: torch.Size([2, 4, 454, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 455, 128]), Value: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[8084], [264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 454\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The\n",
      "New token: ' overall' (id: 8084)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 452])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15853.76MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 456])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15853.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.53MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.53MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 455, generated_ids shape = torch.Size([1, 452])\n",
      "Sequence 1: length = 455, generated_ids shape = torch.Size([1, 456])\n",
      "\n",
      "Found 1 different sequence lengths: [455]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 455\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[8084], [264]]\n",
      "\n",
      "Calculating attention mask length: 455 (current) + 1 (new) = 456\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 456])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 455, 128]), Value shape: torch.Size([1, 4, 455, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 455, 128]), Value shape: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[455], [455]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 456]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 455, 128]), Value: torch.Size([2, 4, 455, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 456, 128]), Value: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[6109], [73549]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 455\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall\n",
      "New token: ' scene' (id: 6109)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 453])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15853.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a\n",
      "New token: ' cloudy' (id: 73549)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 457])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15853.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.64MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.64MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 456, generated_ids shape = torch.Size([1, 453])\n",
      "Sequence 1: length = 456, generated_ids shape = torch.Size([1, 457])\n",
      "\n",
      "Found 1 different sequence lengths: [456]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 456\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[6109], [73549]]\n",
      "\n",
      "Calculating attention mask length: 456 (current) + 1 (new) = 457\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 457])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 456, 128]), Value shape: torch.Size([1, 4, 456, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 456, 128]), Value shape: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[456], [456]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 457]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 456, 128]), Value: torch.Size([2, 4, 456, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 457, 128]), Value: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[374], [1899]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 456\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene\n",
      "New token: ' is' (id: 374)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 454])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15854.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy\n",
      "New token: ' day' (id: 1899)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 458])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15854.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.75MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.75MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 457, generated_ids shape = torch.Size([1, 454])\n",
      "Sequence 1: length = 457, generated_ids shape = torch.Size([1, 458])\n",
      "\n",
      "Found 1 different sequence lengths: [457]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 457\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[374], [1899]]\n",
      "\n",
      "Calculating attention mask length: 457 (current) + 1 (new) = 458\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 458])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 457, 128]), Value shape: torch.Size([1, 4, 457, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 457, 128]), Value shape: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[457], [457]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 458]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 457, 128]), Value: torch.Size([2, 4, 457, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 458, 128]), Value: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[8885], [13]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 457\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is\n",
      "New token: ' bath' (id: 8885)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 455])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15854.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 459])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15854.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.86MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.86MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 458, generated_ids shape = torch.Size([1, 455])\n",
      "Sequence 1: length = 458, generated_ids shape = torch.Size([1, 459])\n",
      "\n",
      "Found 1 different sequence lengths: [458]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 458\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[8885], [13]]\n",
      "\n",
      "Calculating attention mask length: 458 (current) + 1 (new) = 459\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 459])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 458, 128]), Value shape: torch.Size([1, 4, 458, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 458, 128]), Value shape: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[458], [458]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 459]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 458, 128]), Value: torch.Size([2, 4, 458, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 459, 128]), Value: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[291], [1096]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 458\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bath\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bath\n",
      "New token: 'ed' (id: 291)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 456])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15854.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day.\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day.\n",
      "New token: ' This' (id: 1096)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 460])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15854.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.98MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.98MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 459, generated_ids shape = torch.Size([1, 456])\n",
      "Sequence 1: length = 459, generated_ids shape = torch.Size([1, 460])\n",
      "\n",
      "Found 1 different sequence lengths: [459]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 459\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[291], [1096]]\n",
      "\n",
      "Calculating attention mask length: 459 (current) + 1 (new) = 460\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 460])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 459, 128]), Value shape: torch.Size([1, 4, 459, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 459, 128]), Value shape: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[459], [459]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 460]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 459, 128]), Value: torch.Size([2, 4, 459, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 460, 128]), Value: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[304], [1615]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 459\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed\n",
      "New token: ' in' (id: 304)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 457])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15854.87MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This\n",
      "New token: ' mon' (id: 1615)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 461])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15854.87MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.09MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.09MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 460, generated_ids shape = torch.Size([1, 457])\n",
      "Sequence 1: length = 460, generated_ids shape = torch.Size([1, 461])\n",
      "\n",
      "Found 1 different sequence lengths: [460]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 460\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[304], [1615]]\n",
      "\n",
      "Calculating attention mask length: 460 (current) + 1 (new) = 461\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 461])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 460, 128]), Value shape: torch.Size([1, 4, 460, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 460, 128]), Value shape: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[460], [460]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 461]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 460, 128]), Value: torch.Size([2, 4, 460, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 461, 128]), Value: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[5810], [4953]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 460\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in\n",
      "New token: ' natural' (id: 5810)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 458])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15855.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This mon\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This mon\n",
      "New token: 'och' (id: 4953)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 462])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15855.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.20MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.20MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 461, generated_ids shape = torch.Size([1, 458])\n",
      "Sequence 1: length = 461, generated_ids shape = torch.Size([1, 462])\n",
      "\n",
      "Found 1 different sequence lengths: [461]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 461\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[5810], [4953]]\n",
      "\n",
      "Calculating attention mask length: 461 (current) + 1 (new) = 462\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 462])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 461, 128]), Value shape: torch.Size([1, 4, 461, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 461, 128]), Value shape: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[461], [461]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 462]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 461, 128]), Value: torch.Size([2, 4, 461, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 462, 128]), Value: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[3100], [98766]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 461\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural\n",
      "New token: ' light' (id: 3100)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 459])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15855.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monoch\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monoch\n",
      "New token: 'romatic' (id: 98766)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 463])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15855.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.32MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.32MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 462, generated_ids shape = torch.Size([1, 459])\n",
      "Sequence 1: length = 462, generated_ids shape = torch.Size([1, 463])\n",
      "\n",
      "Found 1 different sequence lengths: [462]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 462\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[3100], [98766]]\n",
      "\n",
      "Calculating attention mask length: 462 (current) + 1 (new) = 463\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 463])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 462, 128]), Value shape: torch.Size([1, 4, 462, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 462, 128]), Value shape: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[462], [462]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 463]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 462, 128]), Value: torch.Size([2, 4, 462, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 463, 128]), Value: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[11], [1651]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 462\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 460])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15855.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic\n",
      "New token: ' view' (id: 1651)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 464])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15855.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.43MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.43MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 463, generated_ids shape = torch.Size([1, 460])\n",
      "Sequence 1: length = 463, generated_ids shape = torch.Size([1, 464])\n",
      "\n",
      "Found 1 different sequence lengths: [463]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 463\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[11], [1651]]\n",
      "\n",
      "Calculating attention mask length: 463 (current) + 1 (new) = 464\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 464])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 463, 128]), Value shape: torch.Size([1, 4, 463, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 463, 128]), Value shape: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[463], [463]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 464]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 463, 128]), Value: torch.Size([2, 4, 463, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 464, 128]), Value: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[38586], [65059]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 463\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light,\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light,\n",
      "New token: ' highlighting' (id: 38586)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 461])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15855.76MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view\n",
      "New token: ' emphasizes' (id: 65059)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 465])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15855.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.54MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.54MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 464, generated_ids shape = torch.Size([1, 461])\n",
      "Sequence 1: length = 464, generated_ids shape = torch.Size([1, 465])\n",
      "\n",
      "Found 1 different sequence lengths: [464]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 464\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[38586], [65059]]\n",
      "\n",
      "Calculating attention mask length: 464 (current) + 1 (new) = 465\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 465])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 464, 128]), Value shape: torch.Size([1, 4, 464, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 464, 128]), Value shape: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[464], [464]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 465]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 464, 128]), Value: torch.Size([2, 4, 464, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 465, 128]), Value: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 464\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 462])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15855.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 466])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15855.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.66MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.66MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 465, generated_ids shape = torch.Size([1, 462])\n",
      "Sequence 1: length = 465, generated_ids shape = torch.Size([1, 466])\n",
      "\n",
      "Found 1 different sequence lengths: [465]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 465\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [279]]\n",
      "\n",
      "Calculating attention mask length: 465 (current) + 1 (new) = 466\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 466])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 465, 128]), Value shape: torch.Size([1, 4, 465, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 465, 128]), Value shape: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[465], [465]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 466]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 465, 128]), Value: torch.Size([2, 4, 465, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 466, 128]), Value: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[29853], [12872]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 465\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the\n",
      "New token: ' textures' (id: 29853)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 463])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15856.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the\n",
      "New token: ' contrast' (id: 12872)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 467])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15856.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.77MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.77MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 466, generated_ids shape = torch.Size([1, 463])\n",
      "Sequence 1: length = 466, generated_ids shape = torch.Size([1, 467])\n",
      "\n",
      "Found 1 different sequence lengths: [466]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 466\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[29853], [12872]]\n",
      "\n",
      "Calculating attention mask length: 466 (current) + 1 (new) = 467\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 467])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 466, 128]), Value shape: torch.Size([1, 4, 466, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 466, 128]), Value shape: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[466], [466]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 467]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 466, 128]), Value: torch.Size([2, 4, 466, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 467, 128]), Value: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[315], [1948]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 466\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 464])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15856.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast\n",
      "New token: ' between' (id: 1948)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 468])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15856.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.88MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.88MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 467, generated_ids shape = torch.Size([1, 464])\n",
      "Sequence 1: length = 467, generated_ids shape = torch.Size([1, 468])\n",
      "\n",
      "Found 1 different sequence lengths: [467]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 467\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[315], [1948]]\n",
      "\n",
      "Calculating attention mask length: 467 (current) + 1 (new) = 468\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 468])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 467, 128]), Value shape: torch.Size([1, 4, 467, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 467, 128]), Value shape: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[467], [467]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 468]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 467, 128]), Value: torch.Size([2, 4, 467, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 468, 128]), Value: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[2176], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 467\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of\n",
      "New token: ' both' (id: 2176)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 465])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15856.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 469])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15856.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.99MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15804.99MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 468, generated_ids shape = torch.Size([1, 465])\n",
      "Sequence 1: length = 468, generated_ids shape = torch.Size([1, 469])\n",
      "\n",
      "Found 1 different sequence lengths: [468]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 468\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[2176], [279]]\n",
      "\n",
      "Calculating attention mask length: 468 (current) + 1 (new) = 469\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 469])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 468, 128]), Value shape: torch.Size([1, 4, 468, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 468, 128]), Value shape: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[468], [468]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 469]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 468, 128]), Value: torch.Size([2, 4, 468, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 469, 128]), Value: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [13702]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 468\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 466])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15856.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the\n",
      "New token: ' buildings' (id: 13702)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 470])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15856.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.11MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.11MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 469, generated_ids shape = torch.Size([1, 466])\n",
      "Sequence 1: length = 469, generated_ids shape = torch.Size([1, 470])\n",
      "\n",
      "Found 1 different sequence lengths: [469]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 469\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [13702]]\n",
      "\n",
      "Calculating attention mask length: 469 (current) + 1 (new) = 470\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 470])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 469, 128]), Value shape: torch.Size([1, 4, 469, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 469, 128]), Value shape: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[469], [469]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 470]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 469, 128]), Value: torch.Size([2, 4, 469, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 470, 128]), Value: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[41189], [323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 469\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the\n",
      "New token: ' puppy' (id: 41189)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 467])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15857.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 471])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15857.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.22MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.22MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 470, generated_ids shape = torch.Size([1, 467])\n",
      "Sequence 1: length = 470, generated_ids shape = torch.Size([1, 471])\n",
      "\n",
      "Found 1 different sequence lengths: [470]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 470\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[41189], [323]]\n",
      "\n",
      "Calculating attention mask length: 470 (current) + 1 (new) = 471\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 471])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 470, 128]), Value shape: torch.Size([1, 4, 470, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 470, 128]), Value shape: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[470], [470]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 471]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 470, 128]), Value: torch.Size([2, 4, 470, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 471, 128]), Value: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[594], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 470\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy\n",
      "New token: ''s' (id: 594)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 468])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15857.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 472])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15857.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.33MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.33MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 471, generated_ids shape = torch.Size([1, 468])\n",
      "Sequence 1: length = 471, generated_ids shape = torch.Size([1, 472])\n",
      "\n",
      "Found 1 different sequence lengths: [471]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 471\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[594], [279]]\n",
      "\n",
      "Calculating attention mask length: 471 (current) + 1 (new) = 472\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 472])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 471, 128]), Value shape: torch.Size([1, 4, 471, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 471, 128]), Value shape: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[471], [471]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 472]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 471, 128]), Value: torch.Size([2, 4, 471, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 472, 128]), Value: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[18241], [12884]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 471\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's\n",
      "New token: ' fur' (id: 18241)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 469])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15857.54MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the\n",
      "New token: ' sky' (id: 12884)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 473])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15857.54MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.45MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.45MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 472, generated_ids shape = torch.Size([1, 469])\n",
      "Sequence 1: length = 472, generated_ids shape = torch.Size([1, 473])\n",
      "\n",
      "Found 1 different sequence lengths: [472]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 472\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[18241], [12884]]\n",
      "\n",
      "Calculating attention mask length: 472 (current) + 1 (new) = 473\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 473])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 472, 128]), Value shape: torch.Size([1, 4, 472, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 472, 128]), Value shape: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[472], [472]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 473]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 472, 128]), Value: torch.Size([2, 4, 472, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 473, 128]), Value: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[323], [11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 472\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 470])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15857.76MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 474])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15857.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.56MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.56MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 473, generated_ids shape = torch.Size([1, 470])\n",
      "Sequence 1: length = 473, generated_ids shape = torch.Size([1, 474])\n",
      "\n",
      "Found 1 different sequence lengths: [473]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 473\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[323], [11]]\n",
      "\n",
      "Calculating attention mask length: 473 (current) + 1 (new) = 474\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 474])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 473, 128]), Value shape: torch.Size([1, 4, 473, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 473, 128]), Value shape: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[473], [473]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 474]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 473, 128]), Value: torch.Size([2, 4, 473, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 474, 128]), Value: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[279], [46494]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 473\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 471])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15857.99MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky,\n",
      "New token: ' enhancing' (id: 46494)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 475])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15857.99MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.67MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.67MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 474, generated_ids shape = torch.Size([1, 471])\n",
      "Sequence 1: length = 474, generated_ids shape = torch.Size([1, 475])\n",
      "\n",
      "Found 1 different sequence lengths: [474]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 474\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[279], [46494]]\n",
      "\n",
      "Calculating attention mask length: 474 (current) + 1 (new) = 475\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 475])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 474, 128]), Value shape: torch.Size([1, 4, 474, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 474, 128]), Value shape: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[474], [474]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 475]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 474, 128]), Value: torch.Size([2, 4, 474, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 475, 128]), Value: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[19749], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 474\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the\n",
      "New token: ' aged' (id: 19749)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 472])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15858.21MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 476])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15858.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.78MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.78MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 475, generated_ids shape = torch.Size([1, 472])\n",
      "Sequence 1: length = 475, generated_ids shape = torch.Size([1, 476])\n",
      "\n",
      "Found 1 different sequence lengths: [475]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 475\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[19749], [279]]\n",
      "\n",
      "Calculating attention mask length: 475 (current) + 1 (new) = 476\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 476])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 475, 128]), Value shape: torch.Size([1, 4, 475, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 475, 128]), Value shape: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[475], [475]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 476]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 475, 128]), Value: torch.Size([2, 4, 475, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 476, 128]), Value: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[7579], [21771]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 475\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged\n",
      "New token: ' wood' (id: 7579)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 473])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15858.43MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the\n",
      "New token: ' dramatic' (id: 21771)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 477])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15858.43MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.90MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15805.90MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 476, generated_ids shape = torch.Size([1, 473])\n",
      "Sequence 1: length = 476, generated_ids shape = torch.Size([1, 477])\n",
      "\n",
      "Found 1 different sequence lengths: [476]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 476\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[7579], [21771]]\n",
      "\n",
      "Calculating attention mask length: 476 (current) + 1 (new) = 477\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 477])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 476, 128]), Value shape: torch.Size([1, 4, 476, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 476, 128]), Value shape: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[476], [476]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 477]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 476, 128]), Value: torch.Size([2, 4, 476, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 477, 128]), Value: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[23969], [2456]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 476\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood\n",
      "New token: ' beneath' (id: 23969)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 474])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15858.65MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic\n",
      "New token: ' effect' (id: 2456)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 478])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15858.65MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.01MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.01MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 477, generated_ids shape = torch.Size([1, 474])\n",
      "Sequence 1: length = 477, generated_ids shape = torch.Size([1, 478])\n",
      "\n",
      "Found 1 different sequence lengths: [477]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 477\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[23969], [2456]]\n",
      "\n",
      "Calculating attention mask length: 477 (current) + 1 (new) = 478\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 478])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 477, 128]), Value shape: torch.Size([1, 4, 477, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 477, 128]), Value shape: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[477], [477]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 478]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 477, 128]), Value: torch.Size([2, 4, 477, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 478, 128]), Value: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[432], [315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 477\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath\n",
      "New token: ' it' (id: 432)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 475])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15858.88MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 479])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15858.88MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.12MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.12MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 478, generated_ids shape = torch.Size([1, 475])\n",
      "Sequence 1: length = 478, generated_ids shape = torch.Size([1, 479])\n",
      "\n",
      "Found 1 different sequence lengths: [478]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 478\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[432], [315]]\n",
      "\n",
      "Calculating attention mask length: 478 (current) + 1 (new) = 479\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 479])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 478, 128]), Value shape: torch.Size([1, 4, 478, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 478, 128]), Value shape: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[478], [478]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 479]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 478, 128]), Value: torch.Size([2, 4, 478, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 479, 128]), Value: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[13], [279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 478\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 476])\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15859.10MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 480])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15859.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.24MB\n",
      "\n",
      "Active sequences remaining: 2\n",
      "Finished sequences: 0\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.24MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 2\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 479, generated_ids shape = torch.Size([1, 476])\n",
      "Sequence 1: length = 479, generated_ids shape = torch.Size([1, 480])\n",
      "\n",
      "Found 1 different sequence lengths: [479]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 479\n",
      "Number of sequences in this group: 2\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([2, 1])\n",
      "batch_input_ids values: [[13], [279]]\n",
      "\n",
      "Calculating attention mask length: 479 (current) + 1 (new) = 480\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([2, 480])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Sequence 1 - Key shape: torch.Size([1, 4, 479, 128]), Value shape: torch.Size([1, 4, 479, 128])\n",
      "Concatenated - Key shape: torch.Size([2, 4, 479, 128]), Value shape: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([2, 1])\n",
      "position_ids values: [[479], [479]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([2, 480]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([2, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([2, 4, 479, 128]), Value: torch.Size([2, 4, 479, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([2, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([2, 4, 480, 128]), Value: torch.Size([2, 4, 480, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([2, 152064])\n",
      "Next tokens shape: torch.Size([2, 1])\n",
      "Next tokens values: [[151643], [3283]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 479\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 0 Generation State:\n",
      "Original prompt: Describe this image.\n",
      "Currently generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it.\n",
      "\n",
      "Original prompt: Describe this image.\n",
      "Previously generated:  User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it.\n",
      "New token: '<|endoftext|>' (id: 151643)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 477])\n",
      "Sequence 0 finished\n",
      "Memory after processing sequence 0: CPU Memory: 1663.44MB, GPU Memory: 15859.32MB\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the\n",
      "New token: ' city' (id: 3283)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 481])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15859.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15806.35MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15803.76MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 480, generated_ids shape = torch.Size([1, 481])\n",
      "\n",
      "Found 1 different sequence lengths: [480]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 480\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[3283]]\n",
      "\n",
      "Calculating attention mask length: 480 (current) + 1 (new) = 481\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 481])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 480, 128]), Value shape: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[480]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 481]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 480, 128]), Value: torch.Size([1, 4, 480, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 481, 128]), Value: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[594]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 480\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city\n",
      "New token: ''s' (id: 594)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 482])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15830.35MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.27MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.27MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 481, generated_ids shape = torch.Size([1, 482])\n",
      "\n",
      "Found 1 different sequence lengths: [481]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 481\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[594]]\n",
      "\n",
      "Calculating attention mask length: 481 (current) + 1 (new) = 482\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 482])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 481, 128]), Value shape: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[481]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 482]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 481, 128]), Value: torch.Size([1, 4, 481, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 482, 128]), Value: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[12140]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 481\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's\n",
      "New token: ' vertical' (id: 12140)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 483])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15803.93MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.33MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.33MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 482, generated_ids shape = torch.Size([1, 483])\n",
      "\n",
      "Found 1 different sequence lengths: [482]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 482\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[12140]]\n",
      "\n",
      "Calculating attention mask length: 482 (current) + 1 (new) = 483\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 483])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 482, 128]), Value shape: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[482]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 483]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 482, 128]), Value: torch.Size([1, 4, 482, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 483, 128]), Value: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[505]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 482\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical\n",
      "New token: ' ex' (id: 505)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 484])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.04MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.39MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.39MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 483, generated_ids shape = torch.Size([1, 484])\n",
      "\n",
      "Found 1 different sequence lengths: [483]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 483\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[505]]\n",
      "\n",
      "Calculating attention mask length: 483 (current) + 1 (new) = 484\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 484])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 483, 128]), Value shape: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[483]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 484]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 483, 128]), Value: torch.Size([1, 4, 483, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 484, 128]), Value: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[94419]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 483\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical ex\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical ex\n",
      "New token: 'panse' (id: 94419)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 485])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.15MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.45MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.45MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 484, generated_ids shape = torch.Size([1, 485])\n",
      "\n",
      "Found 1 different sequence lengths: [484]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 484\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[94419]]\n",
      "\n",
      "Calculating attention mask length: 484 (current) + 1 (new) = 485\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 485])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 484, 128]), Value shape: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[484]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 485]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 484, 128]), Value: torch.Size([1, 4, 484, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 485, 128]), Value: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[382]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 484\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse\n",
      "New token: '.\n",
      "\n",
      "' (id: 382)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 486])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.27MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.51MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.51MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 485, generated_ids shape = torch.Size([1, 486])\n",
      "\n",
      "Found 1 different sequence lengths: [485]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 485\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[382]]\n",
      "\n",
      "Calculating attention mask length: 485 (current) + 1 (new) = 486\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 486])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 485, 128]), Value shape: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[485]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 486]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 485, 128]), Value: torch.Size([1, 4, 485, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 486, 128]), Value: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[27489]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 485\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "\n",
      "New token: 'Overall' (id: 27489)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 487])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.38MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.57MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.57MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 486, generated_ids shape = torch.Size([1, 487])\n",
      "\n",
      "Found 1 different sequence lengths: [486]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 486\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[27489]]\n",
      "\n",
      "Calculating attention mask length: 486 (current) + 1 (new) = 487\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 487])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 486, 128]), Value shape: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[486]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 487]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 486, 128]), Value: torch.Size([1, 4, 486, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 487, 128]), Value: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 486\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 488])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.49MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.62MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.62MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 487, generated_ids shape = torch.Size([1, 488])\n",
      "\n",
      "Found 1 different sequence lengths: [487]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 487\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[11]]\n",
      "\n",
      "Calculating attention mask length: 487 (current) + 1 (new) = 488\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 488])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 487, 128]), Value shape: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[487]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 488]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 487, 128]), Value: torch.Size([1, 4, 487, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 488, 128]), Value: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 487\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall,\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 489])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.61MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.68MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.68MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 488, generated_ids shape = torch.Size([1, 489])\n",
      "\n",
      "Found 1 different sequence lengths: [488]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 488\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[279]]\n",
      "\n",
      "Calculating attention mask length: 488 (current) + 1 (new) = 489\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 489])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 488, 128]), Value shape: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[488]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 489]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 488, 128]), Value: torch.Size([1, 4, 488, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 489, 128]), Value: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[2168]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 488\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the\n",
      "New token: ' image' (id: 2168)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 490])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.72MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.74MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.74MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 489, generated_ids shape = torch.Size([1, 490])\n",
      "\n",
      "Found 1 different sequence lengths: [489]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 489\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[2168]]\n",
      "\n",
      "Calculating attention mask length: 489 (current) + 1 (new) = 490\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 490])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 489, 128]), Value shape: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[489]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 490]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 489, 128]), Value: torch.Size([1, 4, 489, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 490, 128]), Value: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[2355]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 489\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image\n",
      "New token: ' power' (id: 2355)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 491])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.83MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.80MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.80MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 490, generated_ids shape = torch.Size([1, 491])\n",
      "\n",
      "Found 1 different sequence lengths: [490]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 490\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[2355]]\n",
      "\n",
      "Calculating attention mask length: 490 (current) + 1 (new) = 491\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 491])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 490, 128]), Value shape: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[490]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 491]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 490, 128]), Value: torch.Size([1, 4, 490, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 491, 128]), Value: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[3641]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 490\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image power\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image power\n",
      "New token: 'fully' (id: 3641)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 492])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15804.95MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.86MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.86MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 491, generated_ids shape = torch.Size([1, 492])\n",
      "\n",
      "Found 1 different sequence lengths: [491]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 491\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[3641]]\n",
      "\n",
      "Calculating attention mask length: 491 (current) + 1 (new) = 492\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 492])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 491, 128]), Value shape: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[491]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 492]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 491, 128]), Value: torch.Size([1, 4, 491, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 492, 128]), Value: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[390]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 491\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully\n",
      "New token: ' con' (id: 390)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 493])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.06MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.92MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.92MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 492, generated_ids shape = torch.Size([1, 493])\n",
      "\n",
      "Found 1 different sequence lengths: [492]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 492\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[390]]\n",
      "\n",
      "Calculating attention mask length: 492 (current) + 1 (new) = 493\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 493])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 492, 128]), Value shape: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[492]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 493]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 492, 128]), Value: torch.Size([1, 4, 492, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 493, 128]), Value: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[49269]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 492\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully con\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully con\n",
      "New token: 'veys' (id: 49269)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 494])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.17MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.98MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.98MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 493, generated_ids shape = torch.Size([1, 494])\n",
      "\n",
      "Found 1 different sequence lengths: [493]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 493\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[49269]]\n",
      "\n",
      "Calculating attention mask length: 493 (current) + 1 (new) = 494\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 494])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 493, 128]), Value shape: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[493]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 494]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 493, 128]), Value: torch.Size([1, 4, 493, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 494, 128]), Value: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[279]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 493\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys\n",
      "New token: ' the' (id: 279)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 495])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.29MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.03MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.03MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 494, generated_ids shape = torch.Size([1, 495])\n",
      "\n",
      "Found 1 different sequence lengths: [494]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 494\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[279]]\n",
      "\n",
      "Calculating attention mask length: 494 (current) + 1 (new) = 495\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 495])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 494, 128]), Value shape: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[494]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 495]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 494, 128]), Value: torch.Size([1, 4, 494, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 495, 128]), Value: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[6662]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 494\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the\n",
      "New token: ' grand' (id: 6662)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 496])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.40MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.09MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.09MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 495, generated_ids shape = torch.Size([1, 496])\n",
      "\n",
      "Found 1 different sequence lengths: [495]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 495\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[6662]]\n",
      "\n",
      "Calculating attention mask length: 495 (current) + 1 (new) = 496\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 496])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 495, 128]), Value shape: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[495]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 496]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 495, 128]), Value: torch.Size([1, 4, 495, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 496, 128]), Value: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[12559]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 495\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grand\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grand\n",
      "New token: 'eur' (id: 12559)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 497])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.51MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.15MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.15MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 496, generated_ids shape = torch.Size([1, 497])\n",
      "\n",
      "Found 1 different sequence lengths: [496]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 496\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[12559]]\n",
      "\n",
      "Calculating attention mask length: 496 (current) + 1 (new) = 497\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 497])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 496, 128]), Value shape: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[496]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 497]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 496, 128]), Value: torch.Size([1, 4, 496, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 497, 128]), Value: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 496\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 498])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.62MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.21MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.21MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 497, generated_ids shape = torch.Size([1, 498])\n",
      "\n",
      "Found 1 different sequence lengths: [497]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 497\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[323]]\n",
      "\n",
      "Calculating attention mask length: 497 (current) + 1 (new) = 498\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 498])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 497, 128]), Value shape: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[497]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 498]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 497, 128]), Value: torch.Size([1, 4, 497, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 498, 128]), Value: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[17457]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 497\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and\n",
      "New token: ' density' (id: 17457)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 499])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.74MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.27MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.27MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 498, generated_ids shape = torch.Size([1, 499])\n",
      "\n",
      "Found 1 different sequence lengths: [498]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 498\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[17457]]\n",
      "\n",
      "Calculating attention mask length: 498 (current) + 1 (new) = 499\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 499])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 498, 128]), Value shape: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[498]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 499]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 498, 128]), Value: torch.Size([1, 4, 498, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 499, 128]), Value: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[315]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 498\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density\n",
      "New token: ' of' (id: 315)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 500])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.85MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.33MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.33MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 499, generated_ids shape = torch.Size([1, 500])\n",
      "\n",
      "Found 1 different sequence lengths: [499]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 499\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[315]]\n",
      "\n",
      "Calculating attention mask length: 499 (current) + 1 (new) = 500\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 500])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 499, 128]), Value shape: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[499]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 500]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 499, 128]), Value: torch.Size([1, 4, 499, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 500, 128]), Value: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[1532]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 499\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of\n",
      "New token: ' New' (id: 1532)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 501])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15805.96MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.38MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.38MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 500, generated_ids shape = torch.Size([1, 501])\n",
      "\n",
      "Found 1 different sequence lengths: [500]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 500\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[1532]]\n",
      "\n",
      "Calculating attention mask length: 500 (current) + 1 (new) = 501\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 501])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 500, 128]), Value shape: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[500]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 501]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 500, 128]), Value: torch.Size([1, 4, 500, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 501, 128]), Value: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[4261]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 500\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New\n",
      "New token: ' York' (id: 4261)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 502])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.08MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.44MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.44MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 501, generated_ids shape = torch.Size([1, 502])\n",
      "\n",
      "Found 1 different sequence lengths: [501]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 501\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[4261]]\n",
      "\n",
      "Calculating attention mask length: 501 (current) + 1 (new) = 502\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 502])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 501, 128]), Value shape: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[501]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 502]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 501, 128]), Value: torch.Size([1, 4, 501, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 502, 128]), Value: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[4311]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 501\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York\n",
      "New token: ' City' (id: 4311)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 503])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.19MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.50MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.50MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 502, generated_ids shape = torch.Size([1, 503])\n",
      "\n",
      "Found 1 different sequence lengths: [502]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 502\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[4311]]\n",
      "\n",
      "Calculating attention mask length: 502 (current) + 1 (new) = 503\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 503])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 502, 128]), Value shape: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[502]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 503]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 502, 128]), Value: torch.Size([1, 4, 502, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 503, 128]), Value: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[11]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 502\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City\n",
      "New token: ',' (id: 11)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 504])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.30MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.56MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.56MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 503, generated_ids shape = torch.Size([1, 504])\n",
      "\n",
      "Found 1 different sequence lengths: [503]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 503\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[11]]\n",
      "\n",
      "Calculating attention mask length: 503 (current) + 1 (new) = 504\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 504])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 503, 128]), Value shape: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[503]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 504]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 503, 128]), Value: torch.Size([1, 4, 503, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 504, 128]), Value: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[66808]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 503\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City,\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City,\n",
      "New token: ' showcasing' (id: 66808)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 505])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.42MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.62MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.62MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 504, generated_ids shape = torch.Size([1, 505])\n",
      "\n",
      "Found 1 different sequence lengths: [504]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 504\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[66808]]\n",
      "\n",
      "Calculating attention mask length: 504 (current) + 1 (new) = 505\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 505])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 504, 128]), Value shape: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[504]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 505]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 504, 128]), Value: torch.Size([1, 4, 504, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 505, 128]), Value: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[1181]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 504\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 506])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.53MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.68MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.68MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 505, generated_ids shape = torch.Size([1, 506])\n",
      "\n",
      "Found 1 different sequence lengths: [505]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 505\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[1181]]\n",
      "\n",
      "Calculating attention mask length: 505 (current) + 1 (new) = 506\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 506])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 505, 128]), Value shape: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[505]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 506]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 505, 128]), Value: torch.Size([1, 4, 505, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 506, 128]), Value: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[2639]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 505\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its\n",
      "New token: ' status' (id: 2639)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 507])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.64MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.74MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.74MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 506, generated_ids shape = torch.Size([1, 507])\n",
      "\n",
      "Found 1 different sequence lengths: [506]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 506\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[2639]]\n",
      "\n",
      "Calculating attention mask length: 506 (current) + 1 (new) = 507\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 507])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 506, 128]), Value shape: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[506]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 507]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 506, 128]), Value: torch.Size([1, 4, 506, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 507, 128]), Value: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[438]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 506\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status\n",
      "New token: ' as' (id: 438)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 508])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.76MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.79MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.79MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 507, generated_ids shape = torch.Size([1, 508])\n",
      "\n",
      "Found 1 different sequence lengths: [507]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 507\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[438]]\n",
      "\n",
      "Calculating attention mask length: 507 (current) + 1 (new) = 508\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 508])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 507, 128]), Value shape: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[507]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 508]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 507, 128]), Value: torch.Size([1, 4, 507, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 508, 128]), Value: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[264]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 507\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as\n",
      "New token: ' a' (id: 264)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 509])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.87MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.85MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.85MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 508, generated_ids shape = torch.Size([1, 509])\n",
      "\n",
      "Found 1 different sequence lengths: [508]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 508\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[264]]\n",
      "\n",
      "Calculating attention mask length: 508 (current) + 1 (new) = 509\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 509])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 508, 128]), Value shape: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[508]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 509]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 508, 128]), Value: torch.Size([1, 4, 508, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 509, 128]), Value: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[3644]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 508\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a\n",
      "New token: ' global' (id: 3644)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 510])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15806.98MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.91MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.91MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 509, generated_ids shape = torch.Size([1, 510])\n",
      "\n",
      "Found 1 different sequence lengths: [509]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 509\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[3644]]\n",
      "\n",
      "Calculating attention mask length: 509 (current) + 1 (new) = 510\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 510])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 509, 128]), Value shape: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[509]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 510]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 509, 128]), Value: torch.Size([1, 4, 509, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 510, 128]), Value: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[2270]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 509\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global\n",
      "New token: ' met' (id: 2270)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 511])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15807.10MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.97MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15778.97MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 510, generated_ids shape = torch.Size([1, 511])\n",
      "\n",
      "Found 1 different sequence lengths: [510]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 510\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[2270]]\n",
      "\n",
      "Calculating attention mask length: 510 (current) + 1 (new) = 511\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 511])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 510, 128]), Value shape: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[510]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 511]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 510, 128]), Value: torch.Size([1, 4, 510, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 511, 128]), Value: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[54322]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 510\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global met\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global met\n",
      "New token: 'ropolis' (id: 54322)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 512])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15807.21MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.03MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.03MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 511, generated_ids shape = torch.Size([1, 512])\n",
      "\n",
      "Found 1 different sequence lengths: [511]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 511\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[54322]]\n",
      "\n",
      "Calculating attention mask length: 511 (current) + 1 (new) = 512\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 512])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 511, 128]), Value shape: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[511]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 512]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 511, 128]), Value: torch.Size([1, 4, 511, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 512, 128]), Value: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[1526]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 511\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis\n",
      "New token: ' through' (id: 1526)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 513])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15807.32MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.09MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.09MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 512, generated_ids shape = torch.Size([1, 513])\n",
      "\n",
      "Found 1 different sequence lengths: [512]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 512\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[1526]]\n",
      "\n",
      "Calculating attention mask length: 512 (current) + 1 (new) = 513\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 513])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 512, 128]), Value shape: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[512]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 513]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 512, 128]), Value: torch.Size([1, 4, 512, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 513, 128]), Value: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[1181]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 512\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through\n",
      "New token: ' its' (id: 1181)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 514])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15807.93MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.64MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.64MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 513, generated_ids shape = torch.Size([1, 514])\n",
      "\n",
      "Found 1 different sequence lengths: [513]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 513\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[1181]]\n",
      "\n",
      "Calculating attention mask length: 513 (current) + 1 (new) = 514\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 514])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 513, 128]), Value shape: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[513]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 514]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 513, 128]), Value: torch.Size([1, 4, 513, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 514, 128]), Value: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[15978]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 513\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its\n",
      "New token: ' impressive' (id: 15978)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 515])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.04MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.70MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.70MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 514, generated_ids shape = torch.Size([1, 515])\n",
      "\n",
      "Found 1 different sequence lengths: [514]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 514\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[15978]]\n",
      "\n",
      "Calculating attention mask length: 514 (current) + 1 (new) = 515\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 515])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 514, 128]), Value shape: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[514]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 515]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 514, 128]), Value: torch.Size([1, 4, 514, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 515, 128]), Value: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[15662]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 514\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive\n",
      "New token: ' urban' (id: 15662)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 516])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.15MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.75MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.75MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 515, generated_ids shape = torch.Size([1, 516])\n",
      "\n",
      "Found 1 different sequence lengths: [515]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 515\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[15662]]\n",
      "\n",
      "Calculating attention mask length: 515 (current) + 1 (new) = 516\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 516])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 515, 128]), Value shape: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[515]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 516]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 515, 128]), Value: torch.Size([1, 4, 515, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 516, 128]), Value: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[17646]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 515\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban\n",
      "New token: ' architecture' (id: 17646)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 517])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.26MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.81MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.81MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 516, generated_ids shape = torch.Size([1, 517])\n",
      "\n",
      "Found 1 different sequence lengths: [516]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 516\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[17646]]\n",
      "\n",
      "Calculating attention mask length: 516 (current) + 1 (new) = 517\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 517])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 516, 128]), Value shape: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[516]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 517]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 516, 128]), Value: torch.Size([1, 4, 516, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 517, 128]), Value: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[323]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 516\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture\n",
      "New token: ' and' (id: 323)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 518])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.37MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.86MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.86MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 517, generated_ids shape = torch.Size([1, 518])\n",
      "\n",
      "Found 1 different sequence lengths: [517]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 517\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[323]]\n",
      "\n",
      "Calculating attention mask length: 517 (current) + 1 (new) = 518\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 518])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 517, 128]), Value shape: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[517]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 518]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 517, 128]), Value: torch.Size([1, 4, 517, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 518, 128]), Value: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[32538]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 517\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and\n",
      "New token: ' sheer' (id: 32538)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 519])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.48MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.92MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.92MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 518, generated_ids shape = torch.Size([1, 519])\n",
      "\n",
      "Found 1 different sequence lengths: [518]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 518\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[32538]]\n",
      "\n",
      "Calculating attention mask length: 518 (current) + 1 (new) = 519\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 519])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 518, 128]), Value shape: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[518]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 519]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 518, 128]), Value: torch.Size([1, 4, 518, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 519, 128]), Value: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[5452]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 518\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer\n",
      "New token: ' scale' (id: 5452)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 520])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.59MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.97MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15779.97MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 519, generated_ids shape = torch.Size([1, 520])\n",
      "\n",
      "Found 1 different sequence lengths: [519]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 519\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[5452]]\n",
      "\n",
      "Calculating attention mask length: 519 (current) + 1 (new) = 520\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 520])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 519, 128]), Value shape: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[519]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 520]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 519, 128]), Value: torch.Size([1, 4, 519, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 520, 128]), Value: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[13]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 519\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale\n",
      "New token: '.' (id: 13)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 521])\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.70MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15780.03MB\n",
      "\n",
      "Active sequences remaining: 1\n",
      "Finished sequences: 1\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15780.03MB\n",
      "\n",
      "==================================================\n",
      "Processing subsequent sequences\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "ENTERING PROCESS_SUBSEQUENT_SEQUENCES\n",
      "Number of sequences to process: 1\n",
      "Number of layers: 28\n",
      "Device: cuda\n",
      "================================================================================\n",
      "\n",
      "Generation Config:\n",
      "max_new_tokens: 1\n",
      "pad_token_id: 151643\n",
      "eos_token_id: 151643\n",
      "\n",
      "Grouping sequences by sequence length...\n",
      "Sequence 0: length = 520, generated_ids shape = torch.Size([1, 521])\n",
      "\n",
      "Found 1 different sequence lengths: [520]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Processing sequence group with seq_len = 520\n",
      "Number of sequences in this group: 1\n",
      "\n",
      "Preparing batch inputs...\n",
      "Collecting last tokens from each sequence...\n",
      "batch_input_ids shape: torch.Size([1, 1])\n",
      "batch_input_ids values: [[13]]\n",
      "\n",
      "Calculating attention mask length: 520 (current) + 1 (new) = 521\n",
      "Creating attention mask...\n",
      "batch_attention_mask shape: torch.Size([1, 521])\n",
      "\n",
      "Stacking past key values...\n",
      "\n",
      "Processing layer 0\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 1\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 2\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 3\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 4\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 5\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 6\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 7\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 8\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 9\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 10\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 11\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 12\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 13\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 14\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 15\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 16\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 17\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 18\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 19\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 20\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 21\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 22\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 23\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 24\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 25\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 26\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Processing layer 27\n",
      "Sequence 0 - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "Concatenated - Key shape: torch.Size([1, 4, 520, 128]), Value shape: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Model uses position IDs. Creating position tensor...\n",
      "position_ids shape: torch.Size([1, 1])\n",
      "position_ids values: [[520]]\n",
      "\n",
      "Preparing final model inputs...\n",
      "\n",
      "Model input shapes:\n",
      "input_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "attention_mask: shape=torch.Size([1, 521]), dtype=torch.float16, device=cuda:0\n",
      "position_ids: shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0\n",
      "past_key_values: 28 layers\n",
      "First layer shapes - Key: torch.Size([1, 4, 520, 128]), Value: torch.Size([1, 4, 520, 128])\n",
      "\n",
      "Starting model forward pass...\n",
      "Running model forward pass...\n",
      "\n",
      "Model outputs received:\n",
      "Logits shape: torch.Size([1, 1, 152064])\n",
      "Past key values: 28 layers\n",
      "First layer past_key_values shapes - Key: torch.Size([1, 4, 521, 128]), Value: torch.Size([1, 4, 521, 128])\n",
      "\n",
      "Computing next tokens...\n",
      "Next token logits shape: torch.Size([1, 152064])\n",
      "Next tokens shape: torch.Size([1, 1])\n",
      "Next tokens values: [[151643]]\n",
      "\n",
      "Creating result object...\n",
      "Result object created successfully\n",
      "\n",
      "Added results for sequence group with seq_len = 520\n",
      "Number of results so far: 1\n",
      "\n",
      "Completed all sequence groups\n",
      "Total number of results: 1\n",
      "================================================================================\n",
      "\n",
      "Sequence 1 Generation State:\n",
      "Original prompt: What do you see in this picture?\n",
      "Currently generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale.\n",
      "\n",
      "Original prompt: What do you see in this picture?\n",
      "Previously generated:  User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale.\n",
      "New token: '<|endoftext|>' (id: 151643)\n",
      "Next token shape: torch.Size([1, 1])\n",
      "Updated generated_ids shape: torch.Size([1, 522])\n",
      "Sequence 1 finished\n",
      "Memory after processing sequence 1: CPU Memory: 1663.44MB, GPU Memory: 15808.81MB\n",
      "Memory after batch cleanup: CPU Memory: 1663.44MB, GPU Memory: 15780.08MB\n",
      "\n",
      "Active sequences remaining: 0\n",
      "Finished sequences: 2\n",
      "Memory after sequence cleanup: CPU Memory: 1663.44MB, GPU Memory: 15777.49MB\n",
      "\n",
      "Sequence processing completed\n",
      "Final memory usage: CPU Memory: 1663.44MB, GPU Memory: 15777.49MB\n",
      "\n",
      "Generation Results:\n",
      "==================================================\n",
      "\n",
      "Sequence 0:\n",
      "Full text:\n",
      " User: Describe this image. Assistant: This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it.\n",
      "\n",
      "Response:\n",
      " This photograph captures a small black Labrador Retriever puppy, likely around six months old, sitting on a weathered wooden deck. The deck's planks, which are a mix of light and dark brown with visible cracks and knots, provide a rustic backdrop. The puppy, with its sleek, short black fur, is positioned in the center of the image, looking up at the camera with its expressive brown eyes. Its ears are slightly floppy, and its tail is perked up, adding to its attentive and curious demeanor. The puppy's front paws are visible, while its back paws are tucked underneath its body. The overall scene is bathed in natural light, highlighting the textures of both the puppy's fur and the aged wood beneath it.\n",
      "\n",
      "Total tokens: 477\n",
      "Response tokens: 152\n",
      "--------------------------------------------------\n",
      "\n",
      "Sequence 1:\n",
      "Full text:\n",
      " User: What do you see in this picture? Assistant: The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale.\n",
      "\n",
      "Response:\n",
      " The image shows a striking black and white aerial view of New York City's iconic skyline. The photograph captures the dense urban landscape with numerous skyscrapers of varying heights and architectural styles. Some buildings have pointed spires, while others feature flat roofs.\n",
      "\n",
      "The composition is dominated by a mix of older art deco structures and more modern glass and steel buildings, creating a fascinating juxtaposition of architectural eras. The buildings are tightly packed together, forming a complex and intricate cityscape that stretches as far as the eye can see.\n",
      "\n",
      "The sky appears overcast with a gradient from darker clouds at the top to lighter areas near the horizon, suggesting a cloudy day. This monochromatic view emphasizes the contrast between the buildings and the sky, enhancing the dramatic effect of the city's vertical expanse.\n",
      "\n",
      "Overall, the image powerfully conveys the grandeur and density of New York City, showcasing its status as a global metropolis through its impressive urban architecture and sheer scale.\n",
      "\n",
      "Total tokens: 522\n",
      "Response tokens: 193\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import requests\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    # Enable TF32 for better performance on Ampere GPUs\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "def resize_and_pad_image(image):\n",
    "    \"\"\"Resize image to a fixed size and pad if necessary.\"\"\"\n",
    "    target_size = (224, 224)  # Standard size for many vision models\n",
    "    image = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    return image\n",
    "\n",
    "def debug_processor_output(processor):\n",
    "    \"\"\"Debug function to examine processor output shapes.\"\"\"\n",
    "    image = Image.open(requests.get(\"https://picsum.photos/id/237/536/354\", stream=True).raw)\n",
    "    # image = resize_and_pad_image(image)\n",
    "    \n",
    "    print(\"\\nRunning processor debug...\")\n",
    "    raw_inputs = processor.process(\n",
    "        images=[image],\n",
    "        text=\"Test image.\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    print(\"\\nRaw processor outputs:\")\n",
    "    for k, v in raw_inputs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            print(f\"{k}: {v.shape}\")\n",
    "    return raw_inputs\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage of the process\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_mem = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    gpu_mem = torch.cuda.memory_allocated() / 1024 / 1024 if torch.cuda.is_available() else 0  # MB\n",
    "    return f\"CPU Memory: {cpu_mem:.2f}MB, GPU Memory: {gpu_mem:.2f}MB\"\n",
    "\n",
    "@contextmanager\n",
    "def batch_memory_manager():\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(f\"Memory after batch cleanup: {get_memory_usage()}\")\n",
    "\n",
    "def print_model_config(model):\n",
    "    \"\"\"Print detailed model configuration for debugging.\"\"\"\n",
    "    print(\"\\nModel Configuration:\")\n",
    "    config = model.config\n",
    "    print(\"\\nConfig attributes:\")\n",
    "    for key, value in config.__dict__.items():\n",
    "        if not key.startswith('_'):\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\nModel Structure:\")\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "    print(\"\\nModel Methods:\")\n",
    "    generation_methods = [method for method in dir(model) if 'generate' in method and not method.startswith('_')]\n",
    "    print(\"Available generation methods:\", generation_methods)\n",
    "    \n",
    "    for method in generation_methods:\n",
    "        if hasattr(model, method):\n",
    "            print(f\"\\n{method} method signature:\")\n",
    "            method_obj = getattr(model, method)\n",
    "            if hasattr(method_obj, '__code__'):\n",
    "                print(f\"Arguments: {method_obj.__code__.co_varnames[:method_obj.__code__.co_argcount]}\")\n",
    "    \n",
    "    print(\"\\nTokenizer Information:\")\n",
    "    print(f\"Vocabulary size: {model.config.vocab_size}\")\n",
    "    print(f\"Model max length: {model.config.max_position_embeddings if hasattr(model.config, 'max_position_embeddings') else 'Not specified'}\")\n",
    "\n",
    "def process_single_thread(thread, processor, device):\n",
    "    \"\"\"Process a single thread with image and text.\"\"\"\n",
    "    image = Image.open(requests.get(thread[\"image_url\"], stream=True).raw)\n",
    "    image = resize_and_pad_image(image)\n",
    "    \n",
    "    with torch.cuda.amp.autocast() if device.type == \"cuda\" else nullcontext():\n",
    "        inputs = processor.process(\n",
    "            images=[image],\n",
    "            text=thread[\"text\"],\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    \n",
    "    # Process and reshape inputs\n",
    "    processed_inputs = {}\n",
    "    for k, v in inputs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            if k == \"input_ids\":\n",
    "                processed_inputs[k] = v.unsqueeze(0) if len(v.shape) == 1 else v\n",
    "            elif k == \"images\":\n",
    "                processed_inputs[k] = v.unsqueeze(0) if len(v.shape) < 4 else v\n",
    "            elif k in [\"image_masks\", \"image_input_idx\"]:\n",
    "                processed_inputs[k] = v.reshape(1, 2, -1) if len(v.shape) == 2 else v\n",
    "            else:\n",
    "                processed_inputs[k] = v\n",
    "            processed_inputs[k] = processed_inputs[k].to(device)\n",
    "        else:\n",
    "            processed_inputs[k] = v\n",
    "    \n",
    "    processed_inputs[\"attention_mask\"] = torch.ones_like(\n",
    "        processed_inputs[\"input_ids\"],\n",
    "        dtype=torch.float16 if device.type == \"cuda\" else torch.float32\n",
    "    )\n",
    "    \n",
    "    return processed_inputs\n",
    "\n",
    "def process_subsequent_sequences(subsequent_sequences, model, processor, num_layers, device):\n",
    "    \"\"\"Process subsequent sequence generation with proper attention handling.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ENTERING PROCESS_SUBSEQUENT_SEQUENCES\")\n",
    "    print(f\"Number of sequences to process: {len(subsequent_sequences)}\")\n",
    "    print(f\"Number of layers: {num_layers}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Create generation config\n",
    "        generation_config = GenerationConfig(\n",
    "            max_new_tokens=1,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "            use_cache=True,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        )\n",
    "        print(\"\\nGeneration Config:\")\n",
    "        print(f\"max_new_tokens: {generation_config.max_new_tokens}\")\n",
    "        print(f\"pad_token_id: {generation_config.pad_token_id}\")\n",
    "        print(f\"eos_token_id: {generation_config.eos_token_id}\")\n",
    "\n",
    "        # Group sequences by past_key_values sequence length\n",
    "        print(\"\\nGrouping sequences by sequence length...\")\n",
    "        seq_len_to_sequences = defaultdict(list)\n",
    "        for idx, seq in enumerate(subsequent_sequences):\n",
    "            seq_len = seq[\"past_key_values\"][0][0].shape[2]\n",
    "            seq_len_to_sequences[seq_len].append(seq)\n",
    "            print(f\"Sequence {idx}: length = {seq_len}, generated_ids shape = {seq['generated_ids'].shape}\")\n",
    "        \n",
    "        print(f\"\\nFound {len(seq_len_to_sequences)} different sequence lengths: {list(seq_len_to_sequences.keys())}\")\n",
    "        \n",
    "        results = []\n",
    "        for seq_len, sequences in seq_len_to_sequences.items():\n",
    "            print(\"\\n\" + \"-\"*80)\n",
    "            print(f\"Processing sequence group with seq_len = {seq_len}\")\n",
    "            print(f\"Number of sequences in this group: {len(sequences)}\")\n",
    "            \n",
    "            batch_size = len(sequences)\n",
    "            print(\"\\nPreparing batch inputs...\")\n",
    "            print(\"Collecting last tokens from each sequence...\")\n",
    "            batch_input_ids = torch.cat([seq[\"generated_ids\"][..., -1:] for seq in sequences], dim=0)\n",
    "            print(f\"batch_input_ids shape: {batch_input_ids.shape}\")\n",
    "            print(f\"batch_input_ids values: {batch_input_ids.tolist()}\")\n",
    "            \n",
    "            # Calculate mask length\n",
    "            mask_len = seq_len + generation_config.max_new_tokens\n",
    "            print(f\"\\nCalculating attention mask length: {seq_len} (current) + {generation_config.max_new_tokens} (new) = {mask_len}\")\n",
    "            \n",
    "            # Create attention mask\n",
    "            print(\"Creating attention mask...\")\n",
    "            batch_attention_mask = torch.ones(\n",
    "                (batch_size, mask_len),\n",
    "                dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "                device=device\n",
    "            )\n",
    "            print(f\"batch_attention_mask shape: {batch_attention_mask.shape}\")\n",
    "            \n",
    "            # Stack past key values\n",
    "            print(\"\\nStacking past key values...\")\n",
    "            batch_past_key_values = []\n",
    "            for layer_idx in range(num_layers):\n",
    "                print(f\"\\nProcessing layer {layer_idx}\")\n",
    "                layer_keys = []\n",
    "                layer_values = []\n",
    "                \n",
    "                for seq_idx, seq in enumerate(sequences):\n",
    "                    past_key, past_value = seq[\"past_key_values\"][layer_idx]\n",
    "                    print(f\"Sequence {seq_idx} - Key shape: {past_key.shape}, Value shape: {past_value.shape}\")\n",
    "                    layer_keys.append(past_key)\n",
    "                    layer_values.append(past_value)\n",
    "                \n",
    "                keys = torch.cat(layer_keys, dim=0)\n",
    "                values = torch.cat(layer_values, dim=0)\n",
    "                print(f\"Concatenated - Key shape: {keys.shape}, Value shape: {values.shape}\")\n",
    "                batch_past_key_values.append((keys, values))\n",
    "\n",
    "            # Handle position IDs\n",
    "            position_ids = None\n",
    "            if model.config.use_position_ids:\n",
    "                print(\"\\nModel uses position IDs. Creating position tensor...\")\n",
    "                position_ids = torch.full(\n",
    "                    (batch_size, 1),\n",
    "                    seq_len,\n",
    "                    dtype=torch.long,\n",
    "                    device=device\n",
    "                )\n",
    "                print(f\"position_ids shape: {position_ids.shape}\")\n",
    "                print(f\"position_ids values: {position_ids.tolist()}\")\n",
    "\n",
    "            # Prepare model inputs\n",
    "            print(\"\\nPreparing final model inputs...\")\n",
    "            model_inputs = {\n",
    "                \"input_ids\": batch_input_ids,\n",
    "                \"attention_mask\": batch_attention_mask,\n",
    "                \"position_ids\": position_ids,\n",
    "                \"past_key_values\": batch_past_key_values,\n",
    "                \"use_cache\": True,\n",
    "            }\n",
    "\n",
    "            print(\"\\nModel input shapes:\")\n",
    "            for k, v in model_inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "                elif isinstance(v, list):\n",
    "                    print(f\"{k}: {len(v)} layers\")\n",
    "                    print(f\"First layer shapes - Key: {v[0][0].shape}, Value: {v[0][1].shape}\")\n",
    "\n",
    "            try:\n",
    "                print(\"\\nStarting model forward pass...\")\n",
    "                with torch.cuda.amp.autocast() if device.type == \"cuda\" else nullcontext():\n",
    "                    print(\"Running model forward pass...\")\n",
    "                    outputs = model(\n",
    "                        **model_inputs,\n",
    "                        return_dict=True\n",
    "                    )\n",
    "                    \n",
    "                    print(\"\\nModel outputs received:\")\n",
    "                    print(f\"Logits shape: {outputs.logits.shape}\")\n",
    "                    print(f\"Past key values: {len(outputs.past_key_values)} layers\")\n",
    "                    print(f\"First layer past_key_values shapes - Key: {outputs.past_key_values[0][0].shape}, Value: {outputs.past_key_values[0][1].shape}\")\n",
    "                    \n",
    "                    print(\"\\nComputing next tokens...\")\n",
    "                    next_token_logits = outputs.logits[:, -1, :]\n",
    "                    print(f\"Next token logits shape: {next_token_logits.shape}\")\n",
    "                    \n",
    "                    next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "                    next_tokens = next_tokens.unsqueeze(-1)\n",
    "                    print(f\"Next tokens shape: {next_tokens.shape}\")\n",
    "                    print(f\"Next tokens values: {next_tokens.tolist()}\")\n",
    "\n",
    "                    print(\"\\nCreating result object...\")\n",
    "                    result = type('GenerationResult', (), {\n",
    "                        'logits': outputs.logits,\n",
    "                        'past_key_values': outputs.past_key_values,\n",
    "                        'generated_tokens': next_tokens\n",
    "                    })\n",
    "                    print(\"Result object created successfully\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"\\nERROR DURING GENERATION:\")\n",
    "                print(f\"Exception type: {type(e)}\")\n",
    "                print(f\"Exception message: {str(e)}\")\n",
    "                print(\"Exception args:\", e.args)\n",
    "                print(\"\\nModel input shapes at time of error:\")\n",
    "                for k, v in model_inputs.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "                    elif isinstance(v, list):\n",
    "                        print(f\"{k}: {len(v)} layers\")\n",
    "                        print(f\"First layer shapes - Key: {v[0][0].shape}, Value: {v[0][1].shape}\")\n",
    "                raise\n",
    "\n",
    "            results.append((sequences, result))\n",
    "            print(f\"\\nAdded results for sequence group with seq_len = {seq_len}\")\n",
    "            print(f\"Number of results so far: {len(results)}\")\n",
    "        \n",
    "        print(\"\\nCompleted all sequence groups\")\n",
    "        print(f\"Total number of results: {len(results)}\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_eos_token_id(processor):\n",
    "    return processor.tokenizer.encode(\"<|endoftext|>\")[-1]\n",
    "\n",
    "def process_sequences(model, processor, pending_threads, device, max_new_tokens=200, max_batch_size=4):\n",
    "    \"\"\"Main sequence processing function with fixed dimension handling.\"\"\"\n",
    "    active_sequences = []\n",
    "    finished_sequences = []\n",
    "    sequence_id = 0\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    eos_token_id = get_eos_token_id(processor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        print(\"\\nStarting sequence processing...\")\n",
    "        print(f\"Number of layers: {num_layers}\")\n",
    "        print(f\"EOS token ID: {eos_token_id}\")\n",
    "        print(f\"Initial memory usage: {get_memory_usage()}\")\n",
    "\n",
    "        while pending_threads or active_sequences:\n",
    "            # Fill batch with new threads\n",
    "            while len(active_sequences) < max_batch_size and pending_threads:\n",
    "                thread = pending_threads.pop(0)\n",
    "                inputs = process_single_thread(thread, processor, device)\n",
    "                \n",
    "                sequence = {\n",
    "                    \"id\": sequence_id,\n",
    "                    \"inputs\": inputs,\n",
    "                    \"generated_ids\": inputs[\"input_ids\"].clone(),  # Should be [1, seq_len]\n",
    "                    \"past_key_values\": None,\n",
    "                    \"finished\": False,\n",
    "                    \"max_length\": inputs[\"input_ids\"].size(-1) + max_new_tokens,\n",
    "                    \"prompt_length\": inputs[\"input_ids\"].size(-1),\n",
    "                    \"original_prompt\": thread[\"text\"],  # Store original prompt for debugging\n",
    "                }\n",
    "                active_sequences.append(sequence)\n",
    "                sequence_id += 1\n",
    "                print(f\"\\nInitialized sequence {sequence_id}:\")\n",
    "                print(f\"Input shape: {inputs['input_ids'].shape}\")\n",
    "                print(f\"Generated IDs shape: {sequence['generated_ids'].shape}\")\n",
    "                print(f\"Memory after sequence initialization: {get_memory_usage()}\")\n",
    "\n",
    "            if not active_sequences:\n",
    "                break\n",
    "\n",
    "            # Process sequences\n",
    "            initial_sequences = [seq for seq in active_sequences if seq[\"past_key_values\"] is None]\n",
    "            subsequent_sequences = [seq for seq in active_sequences if seq[\"past_key_values\"] is not None]\n",
    "\n",
    "            # Handle initial sequences\n",
    "            if initial_sequences:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"Processing initial sequences\")\n",
    "                print(\"=\"*50)\n",
    "                \n",
    "                max_input_length = max(seq[\"inputs\"][\"input_ids\"].size(-1) for seq in initial_sequences)\n",
    "                print(f\"Max input length: {max_input_length}\")\n",
    "                \n",
    "                # Prepare batched inputs\n",
    "                with batch_memory_manager():\n",
    "                    batch_inputs = prepare_batch_inputs(initial_sequences, max_input_length, processor, device)\n",
    "                    print(\"\\nPrepared batch inputs:\")\n",
    "                    for k, v in batch_inputs.items():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            print(f\"{k} shape: {v.shape}\")\n",
    "\n",
    "                    # Forward pass\n",
    "                    with torch.cuda.amp.autocast() if device.type == \"cuda\" else nullcontext():\n",
    "                        outputs = model(**batch_inputs)\n",
    "\n",
    "                    # Update sequences\n",
    "                    for idx, seq in enumerate(initial_sequences):\n",
    "                        # Extract past key values\n",
    "                        seq_past_key_values = [\n",
    "                            (outputs.past_key_values[layer_idx][0][idx:idx+1],\n",
    "                            outputs.past_key_values[layer_idx][1][idx:idx+1])\n",
    "                            for layer_idx in range(num_layers)\n",
    "                        ]\n",
    "                        seq[\"past_key_values\"] = seq_past_key_values\n",
    "\n",
    "                        # Get next token and ensure correct dimensions\n",
    "                        next_token_logits = outputs.logits[idx, -1, :]\n",
    "                        next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "                        next_token = next_token.unsqueeze(0)  # Add batch dimension [1, 1]\n",
    "                        \n",
    "                        # Debug logging\n",
    "                        current_text = processor.tokenizer.decode(seq['generated_ids'].squeeze(), skip_special_tokens=True)\n",
    "                        next_token_text = processor.tokenizer.decode(next_token.squeeze())\n",
    "                        print(f\"\\nOriginal prompt: {seq['original_prompt']}\")\n",
    "                        print(f\"Previously generated: {current_text}\")\n",
    "                        print(f\"New token: '{next_token_text}' (id: {next_token.squeeze().item()})\")\n",
    "\n",
    "                        seq[\"generated_ids\"] = torch.cat([seq[\"generated_ids\"], next_token], dim=1)\n",
    "                        seq[\"inputs\"][\"attention_mask\"] = torch.cat([\n",
    "                            seq[\"inputs\"][\"attention_mask\"],\n",
    "                            torch.ones((1, 1), dtype=seq[\"inputs\"][\"attention_mask\"].dtype, device=device)\n",
    "                        ], dim=1)\n",
    "\n",
    "                        if next_token.squeeze().item() == eos_token_id or seq[\"generated_ids\"].shape[1] >= seq[\"max_length\"]:\n",
    "                            seq[\"finished\"] = True\n",
    "                            print(f\"Sequence {seq['id']} finished\")\n",
    "                        \n",
    "                        print(f\"Memory after processing sequence {seq['id']}: {get_memory_usage()}\")\n",
    "\n",
    "            # Handle subsequent sequences\n",
    "            if subsequent_sequences:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"Processing subsequent sequences\")\n",
    "                print(\"=\"*50)\n",
    "                \n",
    "                with batch_memory_manager():\n",
    "                    batch_results = process_subsequent_sequences(\n",
    "                        subsequent_sequences, model, processor, num_layers, device\n",
    "                    )\n",
    "                    \n",
    "                    for sequences, outputs in batch_results:\n",
    "                        for idx, seq in enumerate(sequences):\n",
    "                            print(f\"\\nSequence {seq['id']} Generation State:\")\n",
    "                            print(f\"Original prompt: {seq['original_prompt']}\")\n",
    "                            current_text = processor.tokenizer.decode(seq['generated_ids'].squeeze(), skip_special_tokens=True)\n",
    "                            print(f\"Currently generated: {current_text}\")\n",
    "                            \n",
    "                            # Update past key values\n",
    "                            seq[\"past_key_values\"] = [\n",
    "                                (outputs.past_key_values[layer_idx][0][idx:idx+1],\n",
    "                                outputs.past_key_values[layer_idx][1][idx:idx+1])\n",
    "                                for layer_idx in range(num_layers)\n",
    "                            ]\n",
    "                            \n",
    "                            # Ensure next_token has correct dimensions [1, 1]\n",
    "                            next_token = outputs.generated_tokens[idx].unsqueeze(0)\n",
    "                            if len(next_token.shape) == 1:\n",
    "                                next_token = next_token.unsqueeze(0)\n",
    "                                \n",
    "                            current_text = processor.tokenizer.decode(seq['generated_ids'].squeeze(), skip_special_tokens=True)\n",
    "                            next_token_text = processor.tokenizer.decode(next_token.squeeze())\n",
    "                            print(f\"\\nOriginal prompt: {seq['original_prompt']}\")\n",
    "                            print(f\"Previously generated: {current_text}\")\n",
    "                            print(f\"New token: '{next_token_text}' (id: {next_token.squeeze().item()})\")\n",
    "                            print(f\"Next token shape: {next_token.shape}\")\n",
    "                            \n",
    "                            # Concatenate along sequence length dimension (dim=1)\n",
    "                            seq[\"generated_ids\"] = torch.cat([seq[\"generated_ids\"], next_token], dim=1)\n",
    "                            print(f\"Updated generated_ids shape: {seq['generated_ids'].shape}\")\n",
    "                            \n",
    "                            seq[\"inputs\"][\"attention_mask\"] = torch.cat([\n",
    "                                seq[\"inputs\"][\"attention_mask\"],\n",
    "                                torch.ones((1, 1), dtype=seq[\"inputs\"][\"attention_mask\"].dtype, device=device)\n",
    "                            ], dim=1)\n",
    "\n",
    "                            if next_token.squeeze().item() == eos_token_id or seq[\"generated_ids\"].shape[1] >= seq[\"max_length\"]:\n",
    "                                seq[\"finished\"] = True\n",
    "                                print(f\"Sequence {seq['id']} finished\")\n",
    "                            \n",
    "                            print(f\"Memory after processing sequence {seq['id']}: {get_memory_usage()}\")\n",
    "\n",
    "            # Clean up finished sequences\n",
    "            newly_finished = [seq for seq in active_sequences if seq[\"finished\"]]\n",
    "            for seq in newly_finished:\n",
    "                # Explicitly clear tensors\n",
    "                for k in list(seq[\"inputs\"].keys()):\n",
    "                    if isinstance(seq[\"inputs\"][k], torch.Tensor):\n",
    "                        seq[\"inputs\"][k] = None\n",
    "                seq[\"past_key_values\"] = None\n",
    "                # Don't clear generated_ids yet as we need it for decoding\n",
    "                \n",
    "            # Update active sequences\n",
    "            active_sequences = [seq for seq in active_sequences if not seq[\"finished\"]]\n",
    "            finished_sequences.extend(newly_finished)\n",
    "            \n",
    "            print(f\"\\nActive sequences remaining: {len(active_sequences)}\")\n",
    "            print(f\"Finished sequences: {len(finished_sequences)}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"Memory after sequence cleanup: {get_memory_usage()}\")\n",
    "            \n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\nSequence processing completed\")\n",
    "        print(f\"Final memory usage: {get_memory_usage()}\")\n",
    "    return finished_sequences\n",
    "\n",
    "def prepare_batch_inputs(sequences, max_length, processor, device):\n",
    "    \"\"\"Helper function to prepare batch inputs with consistent dimensions.\"\"\"\n",
    "    batch_inputs = {}\n",
    "    for key in sequences[0][\"inputs\"].keys():\n",
    "        if isinstance(sequences[0][\"inputs\"][key], torch.Tensor):\n",
    "            tensors = []\n",
    "            for seq in sequences:\n",
    "                if key in [\"input_ids\", \"attention_mask\"]:\n",
    "                    tensor = seq[\"inputs\"][key]\n",
    "                    if tensor.size(1) < max_length:\n",
    "                        padding_length = max_length - tensor.size(1)\n",
    "                        padding_value = 0 if key == \"attention_mask\" else processor.tokenizer.pad_token_id\n",
    "                        padding = torch.full(\n",
    "                            (tensor.size(0), padding_length),\n",
    "                            padding_value,\n",
    "                            dtype=tensor.dtype,\n",
    "                            device=device\n",
    "                        )\n",
    "                        tensor = torch.cat([tensor, padding], dim=1)\n",
    "                    tensors.append(tensor)\n",
    "                else:\n",
    "                    tensors.append(seq[\"inputs\"][key])\n",
    "            batch_inputs[key] = torch.cat(tensors, dim=0)\n",
    "        else:\n",
    "            batch_inputs[key] = sequences[0][\"inputs\"][key]\n",
    "\n",
    "    batch_inputs[\"use_cache\"] = True\n",
    "    return batch_inputs\n",
    "\n",
    "def decode_sequences(finished_sequences, processor):\n",
    "    \"\"\"Decode and print generated sequences.\"\"\"\n",
    "    results = []\n",
    "    for seq in finished_sequences:\n",
    "        generated_ids = seq[\"generated_ids\"].squeeze().cpu()\n",
    "        \n",
    "        # Decode full sequence and response\n",
    "        full_text = processor.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "        response_ids = generated_ids[seq[\"prompt_length\"]:]\n",
    "        response_text = processor.tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "        \n",
    "        results.append({\n",
    "            \"sequence_id\": seq[\"id\"],\n",
    "            \"full_text\": full_text,\n",
    "            \"response_text\": response_text,\n",
    "            \"total_tokens\": len(generated_ids),\n",
    "            \"response_tokens\": len(response_ids)\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Load model and processor\n",
    "    model_name = \"allenai/Molmo-7B-D-0924\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    ).to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Print model configuration and debug processor output\n",
    "    print_model_config(model)\n",
    "    debug_output = debug_processor_output(processor)\n",
    "    print(\"\\nDebug output received. Proceeding with main script...\\n\")\n",
    "\n",
    "    # Example threads\n",
    "    pending_threads = [\n",
    "        {\n",
    "            \"image_url\": \"https://picsum.photos/id/237/536/354\",\n",
    "            \"text\": \"Describe this image.\"\n",
    "        },\n",
    "        {\n",
    "            \"image_url\": \"https://picsum.photos/id/238/536/354\",\n",
    "            \"text\": \"What do you see in this picture?\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Process sequences\n",
    "    finished_sequences = process_sequences(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        pending_threads=pending_threads,\n",
    "        device=device,\n",
    "        max_new_tokens=200,\n",
    "        max_batch_size=4\n",
    "    )\n",
    "\n",
    "    # Decode and print results\n",
    "    results = decode_sequences(finished_sequences, processor)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nGeneration Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    for result in results:\n",
    "        print(f\"\\nSequence {result['sequence_id']}:\")\n",
    "        print(f\"Full text:\\n{result['full_text']}\\n\")\n",
    "        print(f\"Response:\\n{result['response_text']}\\n\")\n",
    "        print(f\"Total tokens: {result['total_tokens']}\")\n",
    "        print(f\"Response tokens: {result['response_tokens']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Clean up CUDA cache\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c12d4b-a4e6-4d05-aa21-9cd839efaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
